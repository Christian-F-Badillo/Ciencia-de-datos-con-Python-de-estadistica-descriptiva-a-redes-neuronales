{
  "hash": "0c883f8aa5a02d3d1838ec2c9cfae286",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Prueba de Hipótesis\"\nauthor: \"Christian Badillo\"\nformat: html\ndate: today\norder: 4\n---\n\nDentro del quehacer de la ciencia, una de las tareas más comunes es la de probar hipótesis. En términos generales, una hipótesis es una afirmación que se hace sobre el valor de un parámetro poblacional. Por ejemplo, una hipótesis podría ser que la media de una población es igual a un valor específico. Para probar esta hipótesis, se recolecta una muestra de la población y se calcula la media muestral. Si la media muestral es muy diferente de la media hipotética, entonces se puede concluir que la hipótesis es falsa. En este caso, se dice que la hipótesis es rechazada. Por otro lado, si la media muestral es muy similar a la media hipotética, entonces se puede concluir que la hipótesis es verdadera. En este caso, se dice que la hipótesis es aceptada.\n\nNo debemos tomar tan a la ligera la decisión de rechazar o aceptar una hipótesis. Siempre existe la posibilidad de que la muestra que se recolectó no sea representativa de la población. Por lo tanto, es importante tener en cuenta el error que se comete al rechazar una hipótesis verdadera. Este error se conoce como **error de tipo I**. Por otro lado, también es importante tener en cuenta el error que se comete al aceptar una hipótesis falsa. Este error se conoce como **error de tipo II**. En general, se busca minimizar ambos errores. Sin embargo, es imposible minimizar ambos errores al mismo tiempo. Por lo tanto, se debe tomar una decisión sobre cuál de los dos errores es más grave. Esta decisión depende del contexto en el que se esté trabajando. Pero en general, se prefiere minimizar el error de tipo I.\n\nPara probar una hipótesis, se sigue un procedimiento estándar. \n\n1. Plantear un modelo base o hipótesis nula, normalmente es que el valor de un parámetro poblacional es igual a cero o que la diferencia entre parametros poblacionales es igual a cero. Se denota como $H_0$.\n\n2. Plantear un modelo alternativo o hipótesis alterna, que puede ser que el valor de un parámetro poblacional es diferente de cero o que la diferencia entre parametros poblacionales es diferente de cero. Se denota como $H_1$.\n\n3. Recolectar una muestra de la población y calcular el estadístico de prueba. Esto depende de la hipótesis que se esté probando, el tipo de datos que se tengan y el tamaño de la muestra.\n\n4. Calcular el valor p. El valor p es la probabilidad de obtener un estadístico de prueba tan extremo como el que se obtuvo dado que la hipótesis nula es verdadera. Si el valor p es menor que un nivel de significancia predefinido, entonces se dice que hay evidencia para rechazar la hipótesis nula.\n\nEl valor p depende directamente de los datos y del procedimiento de su recolección. Por si mismo no es suficiente para tomar una decisión. Por lo tanto, es importante tener en cuenta el contexto en el que se está trabajando. Una medida auxiliar es el **poder** de la prueba. El poder de una prueba es la probabilidad de rechazar la hipótesis nula dado que la hipótesis nula es falsa. En general, se busca que el poder de la prueba sea lo más alto posible. Sin embargo, el poder de la prueba depende de varios factores, como el tamaño de la muestra, el nivel de significancia y la magnitud del efecto.\n\nDe mayor importancia que obtener valores p bajos es tener un buen diseño experimental. Un buen diseño experimental es aquel que permite obtener resultados confiables y válidos. Para ello, es importante tener en cuenta varios factores, como el tamaño de la muestra, la selección de la muestra, la recolección de los datos y el análisis de los datos. En general, se busca que el diseño experimental sea lo más simple posible. Sin embargo, es importante tener en cuenta que un diseño experimental simple no siempre es el mejor.\n\nUna medida que se sugiera reportar el **tamaño del efecto** de la prueba. El tamaño del efecto es una medida de la magnitud del efecto que se está estudiando, es de gran importancia en la interpretación de los resultados. Puede ser absoluta o relativo.\n\nExisten distintas medidas del tamaño del efecto, como la diferencia de medias, la razón de medias, la diferencia de proporciones, la razón de proporciones, la correlación, la regresión, entre otras. La elección de la medida del tamaño del efecto depende del contexto en el que se esté trabajando. En general, se busca que el tamaño del efecto sea lo más grande posible. Sin embargo, es importante tener en cuenta que un tamaño del efecto grande no siempre es mejor. Por ejemplo, un tamaño del efecto grande puede ser el resultado de un error en la recolección de los datos.\n\n## Prueba de Hipótesis para la Media de una Población.\n\nSupongamos que tenemos los datos de la estatura de 1000 personas y queremos saber si la media es distinta de 1.70 m. Para ello, planteamos las siguientes hipótesis:\n\n$$H_0: \\mu = 1.70$$\n\n$$H_1: \\mu \\neq 1.70$$\n\nDonde $\\mu$ es la media de la población. Supongamos que la media muestral es de 1.75 m y la desviación estándar es de 0.10 m. Para probar estas hipótesis, calculamos el estadístico de prueba:\n\n$$t = \\frac{\\bar{x} - \\mu}{s/\\sqrt{n}}$$\n\nDonde $\\bar{x}$ es la media muestral, $s$ es la desviación estándar muestral y $n$ es el tamaño de la muestra. En este caso, el valor del estadístico de prueba es:\n\n$$t = \\frac{1.75 - 1.70}{0.10/\\sqrt{1000}} = 15.81$$\n\nPara calcular el valor p, necesitamos la distribución del estadístico de prueba. En este caso, la distribución del estadístico de prueba es una distribución t de Student con 999 grados de libertad. El valor p es la probabilidad de obtener un estadístico de prueba tan extremo como el que se obtuvo dado que la hipótesis nula es verdadera. En este caso, el valor p es:\n\n::: {#4e792387 .cell execution_count=2}\n``` {.python .cell-code}\nimport scipy.stats as stats\n\nt = 15.81\np = 2 * (1 - stats.t.cdf(t, 999))\n\nprint(f'El valor p es {p}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEl valor p es 0.0\n```\n:::\n:::\n\n\nVisualizemos la distribución del estadístico de prueba:\n\n::: {#5c7a0cef .cell execution_count=3}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(-20, 20, 1000)\ny = stats.t.pdf(x, 999)\n\nplt.plot(x, y)\nplt.axvline(t, color='red', linestyle='--')\nplt.xlabel('Estadístico de Prueba')\nplt.ylabel('Densidad')\nplt.title('Distribución del Estadístico de Prueba')\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](hipothesis_testing_files/figure-html/cell-3-output-1.png){width=597 height=449}\n:::\n:::\n\n\nSi definimos un nivel de significancia de 0.05, entonces podemos concluir que hay evidencia para rechazar la hipótesis nula. Por lo tanto, podemos concluir que la media de la población es distinta de 1.70 m.\n\nLa regigión crítica es aquella en la que se rechaza la hipótesis nula, debe sumar el nivel de significancia. Visualicemos la región crítica:\n\n::: {#4c15c0d3 .cell execution_count=4}\n``` {.python .cell-code}\nx = np.linspace(-20, 20, 1000)\ny = stats.t.pdf(x, 999)\n\nplt.plot(x, y)\nplt.axvline(t, color='red', linestyle='--')\n\nt1 = stats.t.ppf(0.025, 999) # 0.025 porque es una prueba de dos colas\nt2 = stats.t.ppf(0.975, 999) # 0.975 porque es una prueba de dos colas\n\nplt.fill_between(x, y, where=(x < t1), color='green', alpha=0.5)\nplt.fill_between(x, y, where=(x > t2), color='green', alpha=0.5)\n\n\nplt.xlabel('Estadístico de Prueba')\nplt.ylabel('Densidad')\nplt.title('Distribución del Estadístico de Prueba')\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](hipothesis_testing_files/figure-html/cell-4-output-1.png){width=597 height=449}\n:::\n:::\n\n\nObservamos que el estadístico de prueba cae en la región crítica. Por lo tanto, podemos concluir que hay evidencia para rechazar la hipótesis nula.\n\nPodemos hacer este test con la función `ttest_1samp` de `scipy.stats`:\n\n::: {#28f9403f .cell execution_count=5}\n``` {.python .cell-code}\nnp.random.seed(123)\nx = np.random.normal(1.75, 0.10, 1000)\n\nresult = stats.ttest_1samp(x, 1.70)\nlower, upper = result.confidence_interval(confidence_level=0.95)\n\nprint(f'El valor p es {result.pvalue}')\nprint(f'El estadístico de prueba es {result.statistic}')\nprint(f\"Los grado de libertad son {result.df}\")\nprint(f\"El intervalo de confianza para la media es [{lower}, {upper}]\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEl valor p es 1.3453036210893457e-43\nEl estadístico de prueba es 14.54152651527113\nLos grado de libertad son 999\nEl intervalo de confianza para la media es [1.7398301232798288, 1.7522570495040128]\n```\n:::\n:::\n\n\n## Prueba de Hipótesis para la Diferencia de Medias de dos Poblaciones.\n\nSupongamos que tenemos los datos de la estatura de 1000 hombres y 1000 mujeres y queremos saber si la media de los hombres es distinta de la media de las mujeres. Para ello, planteamos las siguientes hipótesis:\n\n$$H_0: \\mu_1 - \\mu_2 = 0$$\n\n$$H_1: \\mu_1 - \\mu_2 \\neq 0$$\n\nDonde $\\mu_1$ es la media de los hombres y $\\mu_2$ es la media de las mujeres. Supongamos que la media de los hombres es de 1.75 m, la desviación estándar de los hombres es de 0.10 m, la media de las mujeres es de 1.55 m y la desviación estándar de las mujeres es de 0.10 m. Para probar estas hipótesis, calculamos el estadístico de prueba:\n\n$$t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{s_1^2/n_1 + s_2^2/n_2}}$$\n\nDonde $\\bar{x}_1$ es la media de los hombres, $\\bar{x}_2$ es la media de las mujeres, $s_1$ es la desviación estándar de los hombres, $s_2$ es la desviación estándar de las mujeres, $n_1$ es el tamaño de la muestra de los hombres y $n_2$ es el tamaño de la muestra de las mujeres. En este caso, el valor del estadístico de prueba es:\n\n$$t = \\frac{1.75 - 1.55}{\\sqrt{0.10^2/1000 + 0.10^2/1000}} = 31.62$$\n\nGeneremos datos con python y calculemos el estadístico de prueba:\n\n::: {#8017c434 .cell execution_count=6}\n``` {.python .cell-code}\nnp.random.seed(123)\nx1 = np.random.normal(1.75, 0.10, 1000)\n\nnp.random.seed(123)\nx2 = np.random.normal(1.55, 0.10, 1000)\n\nt = (x1.mean() - x2.mean()) / np.sqrt((x1.var() / 1000) + (x2.var() / 1000))\n\nprint(f'El estadístico de prueba es {t}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEl estadístico de prueba es 44.68616751661976\n```\n:::\n:::\n\n\nPara calcular el valor p, necesitamos la distribución del estadístico de prueba. En este caso, la distribución del estadístico de prueba es una distribución t de Student con 1998 grados de libertad. Los grados se calculan como $n_1 + n_2 - 2$. Visualicemos la distribución del estadístico de prueba, la región crítica y el valor p:\n\n::: {#29f01ef4 .cell execution_count=7}\n``` {.python .cell-code}\nx = np.linspace(-50, 50, 5000)\ny = stats.t.pdf(x, 1998)\n\nfig, ax = plt.subplots(figsize=(10, 5))\n\nax.plot(x, y)\nax.axvline(t, color='red', linestyle='--')\n\nt1 = stats.t.ppf(0.025, 1998) \nt2 = stats.t.ppf(0.975, 1998)\n\nax.fill_between(x, y, where=(x < t1), color='green', alpha=0.5)\nax.fill_between(x, y, where=(x > t2), color='green', alpha=0.5)\n\nplt.xlabel('Estadístico de Prueba')\nplt.ylabel('Densidad')\nplt.title('Distribución del Estadístico de Prueba')\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](hipothesis_testing_files/figure-html/cell-7-output-1.png){width=821 height=449}\n:::\n:::\n\n\nComo el valor p es muy pequeño, podemos concluir que hay evidencia para rechazar la hipótesis nula. Por lo tanto, podemos concluir que la media de los hombres es distinta de la media de las mujeres.\n\nPodemos hacer este test con la función `ttest_ind` de `scipy.stats`:\n\n::: {#d85d5ddd .cell execution_count=8}\n``` {.python .cell-code}\nresult = stats.ttest_ind(x1, x2)\n\nlower, upper = result.confidence_interval(confidence_level=0.95)\n\nprint(f'El valor p es {result.pvalue}')\nprint(f'El estadístico de prueba es {result.statistic}')\nprint(f\"Los grado de libertad son {result.df}\")\nprint(f\"El intervalo de confianza para la diferencia de medias es [{lower}, {upper}]\")\nprint(f\"Diff de medias {x1.mean() - x2.mean()}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEl valor p es 1.0339591135264653e-302\nEl estadístico de prueba es 44.66381884429588\nLos grado de libertad son 1998.0\nEl intervalo de confianza para la diferencia de medias es [0.1912181624160999, 0.2087818375839]\nDiff de medias 0.19999999999999996\n```\n:::\n:::\n\n\nCon `statsmodels` igualmente podemos hacer este test:\n\n::: {#e8f8ed95 .cell execution_count=9}\n``` {.python .cell-code}\nimport statsmodels.api as sm\n\nttest = sm.stats.ttest_ind(x1, x2)\n\nprint(f'El estadístico de prueba es {ttest[0]}')\nprint(f'El valor p es {ttest[1]}')\nprint(f\"Los grado de libertad son {ttest[2]}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEl estadístico de prueba es 44.663818844295825\nEl valor p es 1.033959113527759e-302\nLos grado de libertad son 1998.0\n```\n:::\n:::\n\n\n### Tamaño del Efecto\n\nEl tamaño del efecto es una medida de la magnitud del efecto que se está estudiando. En este caso, el tamaño del efecto es:\n\n$$d = \\frac{\\bar{x}_1 - \\bar{x}_2}{s}$$\n\nDonde $\\bar{x}_1$ es la media de los hombres, $\\bar{x}_2$ es la media de las mujeres, $s$ es la desviación estándár combinada, que Jacob Cohen sugiere que se calcule como:\n\n$$s = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}$$\n\nLa varianza para cada grupo se calcula como:\n\n$$s_i^2 = \\frac{\\sum_{j=1}^{n_1}(x_{ij} - \\bar{x}_i)^2}{n_i - 1}$$\n\nEn esta tabla podemos ver el tamaño del efecto para distintos valores de $d$:\n\n| Tamaño del Efecto | d |\n|-------------------|---|\n| Muy Pequeño | 0.01 |\n| Pequeño | 0.20 |\n| Mediano | 0.50 |\n| Grande | 0.80 |\n| Muy Grande | 1.20 |\n| Enorme | 2.00 |\n\nVamos a crear una función que calcule el tamaño del efecto:\n\n::: {#177b84d8 .cell execution_count=10}\n``` {.python .cell-code}\ndef effect_size(x1, x2):\n    n1 = len(x1)\n    n2 = len(x2)\n    \n    s1 = np.sqrt(np.sum((x1 - x1.mean())**2) / (n1 - 1))\n    s2 = np.sqrt(np.sum((x2 - x2.mean())**2) / (n2 - 1))\n    \n    s = np.sqrt(((n1 - 1) * s1**2 + (n2 - 1) * s2**2) / (n1 + n2 - 2))\n    \n    d = (x1.mean() - x2.mean()) / s\n    \n    return d\n\nd = effect_size(x1, x2)\n\nprint(f'El tamaño del efecto es {d}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEl tamaño del efecto es 1.9974267014116336\n```\n:::\n:::\n\n\nEl efecto es muy grande, por lo que podemos concluir que la diferencia entre las medias de los hombres y las mujeres es muy grande.\n\n## Prueba de Hipótesis para más de dos Poblaciones.\n\nSupongamos que tenemos los datos de la estatura de 1000 personas de tres países distintos y queremos saber si la media de las tres poblaciones es distinta. Para ello, planteamos las siguientes hipótesis:\n\n$$H_0: \\mu_1 = \\mu_2 = \\mu_3$$\n\n$$H_1: \\mu_1 \\neq \\mu_2 \\neq \\mu_3$$\n\nDonde $\\mu_1$ es la media de las personas del país 1, $\\mu_2$ es la media de las personas del país 2 y $\\mu_3$ es la media de las personas del país 3. Supongamos que la media de las personas del país 1 es de 1.75 m, la desviación estándar de las personas del país 1 es de 0.10 m, la media de las personas del país 2 es de 1.55 m, la desviación estándar de las personas del país 2 es de 0.10 m, la media de las personas del país 3 es de 1.65 m y la desviación estándar de las personas del país 3 es de 0.10 m. Para probar estas hipótesis, calculamos el estadístico de prueba:\n\n$$F = \\frac{MS_{\\text{entre}}}{MS_{\\text{dentro}}}$$\n\nDonde $MS_{\\text{entre}}$ es la media de las varianzas entre las poblaciones y $MS_{\\text{dentro}}$ es la media de las varianzas dentro de las poblaciones. \n\n$$MS_{\\text{entre}} = \\frac{\\sum_{i=1}^{k}n_i(\\bar{x}_i - \\bar{x})^2}{k - 1}$$\n\n$$MS_{\\text{dentro}} = \\frac{\\sum_{i=1}^{k}\\sum_{j=1}^{n_i}(x_{ij} - \\bar{x}_i)^2}{n - k}$$\n\nEn este caso, el valor del estadístico de prueba es:\n\n::: {#50fc9115 .cell execution_count=11}\n``` {.python .cell-code}\nnp.random.seed(123)\nx1 = np.random.normal(1.75, 0.10, 1000)\nx2 = np.random.normal(1.55, 0.10, 1000)\nx3 = np.random.normal(1.65, 0.10, 1000)\n\nx = np.concatenate([x1, x2, x3])\n\nMs_between = (1000 * (x1.mean() - x.mean())**2 + 1000 * (x2.mean() - x.mean())**2 + 1000 * (x3.mean() - x.mean())**2) / 2\n\nMs_within = (np.sum((x1 - x1.mean())**2) + np.sum((x2 - x2.mean())**2) + np.sum((x3 - x3.mean())**2)) / 2997\n\nF = Ms_between / Ms_within\n\nprint(f'El estadístico de prueba es {F}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEl estadístico de prueba es 990.6545267572889\n```\n:::\n:::\n\n\nPara calcular el valor p, necesitamos la distribución del estadístico de prueba. En este caso, la distribución del estadístico de prueba es una distribución F de Fisher con 2 y 2998 grados de libertad. Los grados de libertad se calculan como $k - 1$ y $n - k$, donde $k$ es el número de poblaciones y $n$ es el número total de observaciones. Visualicemos la distribución del estadístico de prueba, la región crítica y el valor p:\n\n::: {#8af37305 .cell execution_count=12}\n``` {.python .cell-code}\nx = np.linspace(0, 10, 1000)\ny = stats.f.pdf(x, 2, 2998)\n\nfig, ax = plt.subplots(figsize=(10, 5))\n\nax.plot(x, y, label=f'F(2, 2998), F = {round(F, 2)}')\n\nf1 = stats.f.ppf(0.025, 2, 2998)\nf2 = stats.f.ppf(0.975, 2, 2998)\n\nax.fill_between(x, y, where=(x < f1), color='green', alpha=0.5)\nax.fill_between(x, y, where=(x > f2), color='green', alpha=0.5)\n\nplt.xlabel('Estadístico de Prueba')\nplt.ylabel('Densidad')\nplt.title('Distribución del Estadístico de Prueba')\n\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](hipothesis_testing_files/figure-html/cell-12-output-1.png){width=812 height=449}\n:::\n:::\n\n\nPodemos concluir que hay evidencia para rechazar la hipótesis nula. Por lo tanto, podemos concluir que la media de las tres poblaciones es distinta.\n\nPodemos hacer este test con la función `f_oneway` de `scipy.stats`:\n\n::: {#10fa57fa .cell execution_count=13}\n``` {.python .cell-code}\nresult = stats.f_oneway(x1, x2, x3)\n\nprint(f'El valor p es {result.pvalue}')\nprint(f'El estadístico de prueba es {result.statistic}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEl valor p es 0.0\nEl estadístico de prueba es 990.6545267572892\n```\n:::\n:::\n\n\nCon `statsmodels` igualmente podemos hacer este test:\n\n::: {#c83ae04e .cell execution_count=14}\n``` {.python .cell-code}\nimport statsmodels.api as sm\nimport pandas as pd\nx = np.concatenate([x1, x2, x3])\n\ndf = pd.DataFrame({'x': x, 'group': ['x1'] * 1000 + ['x2'] * 1000 + ['x3'] * 1000})\n\nlinear_model = sm.formula.ols('x ~ group', data=df).fit()\n\nanova = sm.stats.anova_lm(linear_model)\n\nprint(anova)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              df     sum_sq   mean_sq           F  PR(>F)\ngroup        2.0  19.056918  9.528459  990.654527     0.0\nResidual  2997.0  28.826185  0.009618         NaN     NaN\n```\n:::\n:::\n\n\nLa interpretación es que hay evidencia para rechazar la hipótesis nula de igualdad de medias.\n\nPara averiguar cuales medias son distintas podemos hacer un test post-hoc, como el test de Tukey:\n\n::: {#eb9f6004 .cell execution_count=15}\n``` {.python .cell-code}\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd\n\ntukey = pairwise_tukeyhsd(df['x'], df['group'])\n\nprint(tukey)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMultiple Comparison of Means - Tukey HSD, FWER=0.05\n===================================================\ngroup1 group2 meandiff p-adj  lower   upper  reject\n---------------------------------------------------\n    x1     x2  -0.1952   0.0 -0.2055 -0.1849   True\n    x1     x3   -0.095   0.0 -0.1053 -0.0847   True\n    x2     x3   0.1002   0.0  0.0899  0.1105   True\n---------------------------------------------------\n```\n:::\n:::\n\n\nEl resultado nos dice que las medias de las tres poblaciones son distintas entre sí de manera significativa.\n\nSi tuvieramos un grupo de control y varios grupos de tratamiento, podríamos hacer un test de Dunnett:\n\n::: {#9518dfcc .cell execution_count=16}\n``` {.python .cell-code}\nfrom scipy.stats import dunnett\n\nresult = dunnett(x2, x3, control=x1)\n\nprint(result)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDunnett's test (95.0% Confidence Interval)\nComparison               Statistic  p-value  Lower CI  Upper CI\n (Sample 0 - Control)    -44.507     0.000    -0.205    -0.185\n (Sample 1 - Control)    -21.662     0.000    -0.105    -0.085\n\n```\n:::\n:::\n\n\nExisten otros test post-hoc, como el test de Bonferroni, el test de Scheffé, el test de Holm, entre otros. La elección del test post-hoc depende del objetivo del estudio.\n\n",
    "supporting": [
      "hipothesis_testing_files"
    ],
    "filters": [],
    "includes": {}
  }
}