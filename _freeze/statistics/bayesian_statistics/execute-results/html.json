{
  "hash": "f0895339338db5c53b80843f7d6fc7dc",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Introducción a Estadística Bayesiana\"\nauthor: \"Christian Badillo\"\nformat: html\ndate: today\norder: 5\n---\n\nExisten dos enfoques principales en estadística: el enfoque frecuentista y el enfoque bayesiano. En este documento, se presentará una introducción a la estadística bayesiana.\n\nLa filosofía de la estadística bayesiana es diferente a la de la estadística frecuentista. En la estadística bayesiana, se considera que la incertidumbre en los parámetros de un modelo se puede representar mediante una distribución de probabilidad. Por otro lado, en la estadística frecuentista, los parámetros son considerados como valores fijos y la incertidumbre se representa mediante intervalos de confianza, que son estimaciones de la variabilidad de los parámetros dada la muestra.\n\nEn la estadística bayesiana, se considera que los parámetros de un modelo son variables aleatorias y se les asigna una **distribución de probabilidad a priori**. Esta distribución de probabilidad a priori representa el conocimiento previo que se tiene sobre los parámetros antes de observar los datos. Luego, se actualiza esta distribución de probabilidad a priori con los datos observados para obtener la **distribución de probabilidad a posteriori**, que representa el conocimiento actualizado sobre los parámetros después de observar los datos.\n\nPara lograr esta actualización utilizamos el Teorema de Bayes, que establece la relación entre la distribución de probabilidad a priori y la distribución de probabilidad a posteriori. El Teorema de Bayes se define de la siguiente manera:\n\n$$ P(\\theta|X) = \\frac{L(X|\\theta)P(\\theta)}{P(X)} $$\n\nDonde:\n\n- $P(\\theta|X)$ es la distribución de probabilidad a posteriori de los parámetros $\\theta$ dado los datos $X$.\n- $L(X|\\theta)$ es la función de verosimilitud, que representa la verosimilitud de observar los datos $X$ dado los parámetros $\\theta$.\n- $P(\\theta)$ es la distribución de probabilidad a priori de los parámetros $\\theta$.\n\nLa distribución de probabilidad a posteriori se obtiene multiplicando la función de verosimilitud por la distribución de probabilidad a priori y normalizando el resultado. La distribución de probabilidad a posteriori es la distribución de probabilidad de los parámetros $\\theta$ dado los datos $X$ y se utiliza para realizar inferencias sobre los parámetros del modelo. \n\n## Estimación de un Parámetro\n\nSupongamos que lanzamos una moneda varias veces para poder estimar si la moneda tiene truco o esta sesgada. Para poder estimar este parámetro, podemos utilizar la estadística bayesiana. Para ello deberemos seguir los siguientes pasos:\n\n### Paso 1: Definir el Modelo de los Datos\n\nLo primero es encontrar un modelo que describa los datos o en otros términos, encontrar una distribución de probabilidad que describa la probabilidad de obtener una cara o una cruz. En este caso, podemos utilizar una distribución de Bernoulli para modelar la probabilidad de obtener una cara o una cruz en un lanzamiento de moneda. La distribución de Bernoulli se define de la siguiente manera:\n\n$$ L(X|\\theta) = \\theta^x(1-\\theta)^{1-x} $$\n\nDonde:\n\n- $X$ es la variable aleatoria que representa el resultado del lanzamiento de la moneda (0 si es cruz y 1 si es cara).\n- $\\theta$ es el parámetro de la distribución de Bernoulli que representa la probabilidad de obtener una cara en un lanzamiento de moneda.\n\nEl problema es que solo sirve para un lanzamiento en particular y nuestros datos son el resultado de varios lanzamientos. Para poder modelar los datos de varios lanzamientos, podemos utilizar una distribución de Bernoulli generalizada, que se conoce como distribución de Binomial. La distribución de Binomial se define de la siguiente manera:\n\n$$ L(X|\\theta) = \\binom{n}{x}\\theta^x(1-\\theta)^{n-x} $$\n\nDonde $n$ es el número de lanzamientos de la moneda y $x$ es el número de caras obtenidas en los $n$ lanzamientos. Esta distribución representa la probabilidad de obtener $x$ caras en $n$ lanzamientos de una moneda con probabilidad $\\theta$ de obtener una cara, ***pero aquí $\\theta$ es una variable desconocida que queremos estimar y por tanto no representa una distribución de probabilidad***. Será nuestro modelo de los datos o lo que llamamos anteriormente como la **función de verosimilitud**.\n\nVamos a simular datos de un lanzamiento de moneda con $\\theta = 0.65$ y $n = 40$.\n\n::: {#3c28e263 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(101408)\ndatos = np.random.choice([0, 1], size=40, p=[0.35, 0.65])\n\nplt.bar([0, 1], [sum(datos == 0), sum(datos == 1)], color=['red', 'blue'])\nplt.xticks([0, 1], ['Cruz', 'Cara'], fontsize=12)\nplt.ylabel('Frecuencia', fontsize=12)\nplt.title('Resultados de 40 lanzamientos de moneda', fontsize=14, fontweight='bold')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_statistics_files/figure-html/cell-2-output-1.png){width=587 height=436}\n:::\n:::\n\n\nAhora vamos a ver como luce la función de verosimilitud para distintos valores de $\\theta$.\n\n::: {#2579906b .cell execution_count=2}\n``` {.python .cell-code}\nfrom scipy.stats import binom\n\ntheta = np.linspace(0, 1, 1000)\n\nplt.plot(theta, binom.pmf(sum(datos == 1), 40, theta), color='blue')\nplt.xlabel(r'$\\theta$', fontsize=15)\nplt.ylabel(r'$L(X|\\theta)$', fontsize=15)\nplt.title('Función de Verosimilitud', fontsize=20, fontweight='bold')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_statistics_files/figure-html/cell-3-output-1.png){width=607 height=465}\n:::\n:::\n\n\n## Paso 2: Definir la Distribución de Probabilidad a Priori\n\nEl siguiente paso es definir una distribución de probabilidad a priori para el parámetro $\\theta$. La distribución de probabilidad a priori representa el conocimiento previo que se tiene sobre el parámetro $\\theta$ antes de observar los datos. \n\nExisten dos tipos de distribuciones de probabilidad a priori: distribuciones de probabilidad a priori **informativas** y distribuciones de probabilidad a priori **no informativas**. Las distribuciones de probabilidad a priori informativas se utilizan cuando se tiene información previa sobre el parámetro $\\theta$ y se desea incorporar esta información en el análisis. Por otro lado, las distribuciones de probabilidad a priori no informativas se utilizan cuando no se tiene información previa sobre el parámetro $\\theta$ y se desea dejar que los datos guíen la inferencia.\n\nDebemos de pensar primeramente para que rangos nuestro parámetro $\\theta$ puede variar. En este caso, como $\\theta$ es una probabilidad, debe de estar en el rango $[0, 1]$. Una distribución de probabilidad a priori común para el parámetro $\\theta$ es la distribución Beta, que se define de la siguiente manera:\n\n$$ P(\\theta) = \\frac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}{B(\\alpha, \\beta)} $$\n\nDonde:\n\n- $\\alpha$ y $\\beta$ son los parámetros de la distribución Beta.\n- $B(\\alpha, \\beta)$ es la función Beta, que es una constante de normalización.\n\nLa función Beta se ve de la siguiente manera:\n\n$$ B(\\alpha, \\beta) = \\int_0^1 \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}d\\theta $$\n\n\nVeamos como se ve para distintos valores de $\\alpha$ y $\\beta$.\n\n::: {#45d7ee75 .cell execution_count=3}\n``` {.python .cell-code}\nfrom scipy.stats import beta\n\ntheta = np.linspace(0.1, 0.99, 1000)\nalphas = [0.5, 1, 2]\nbetas = [0.5, 1, 2]\n\nplt.figure(figsize=(10, 6))\n\nfor a in alphas:\n    for b in betas:\n        plt.plot(theta, beta.pdf(theta, a, b), label=f'$\\\\alpha={a}, \\\\beta={b}$', alpha=0.7, lw=2)\n\nplt.xlabel(r'$\\theta$', fontsize=15)\nplt.ylabel(r'$P(\\theta)$', fontsize=15)\nplt.title('Distribución de Probabilidad a Priori', fontsize=20, fontweight='bold')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_statistics_files/figure-html/cell-4-output-1.png){width=806 height=539}\n:::\n:::\n\n\nLas formas de la distribución de probabilidad a priori dependen de los valores de los parámetros $\\alpha$ y $\\beta$. Por ejemplo, si $\\alpha = \\beta = 1$, la distribución de probabilidad a priori es uniforme en el intervalo $[0, 1]$. Si $\\alpha = \\beta = 0.5$, la distribución de probabilidad a priori es una distribución de probabilidad a priori no informativa. Si $\\alpha > \\beta$, la distribución de probabilidad a priori se concentra en valores cercanos a 1. Si $\\alpha < \\beta$, la distribución de probabilidad a priori se concentra en valores cercanos a 0.\n\nUsemos valores de $\\alpha = 1$ y $\\beta = 1$ para nuestra distribución de probabilidad a priori.\n\n## Paso 3: Calcular la Distribución de Probabilidad a Posteriori\n\nEl siguiente paso es calcular la distribución de probabilidad a posteriori de los parámetros $\\theta$ dado los datos $X$. Para ello, utilizamos el Teorema de Bayes.\n\n\\begin{equation}\nP(\\theta|X) = \\frac{L(X|\\theta)P(\\theta)}{P(X)} = \\frac{L(X|\\theta)P(\\theta)}{\\int L(X|\\theta)P(\\theta)d\\theta}\n\\end{equation}\n\nVamos a reemplazar la función de verosimilitud y la distribución de probabilidad a priori en la ecuación anterior.\n\n\\begin{align}\nP(\\theta|X) & = \\frac{\\binom{n}{x}\\theta^x(1-\\theta)^{n-x}\\frac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}{B(\\alpha, \\beta)}}{\\int \\binom{n}{x}\\theta^x(1-\\theta)^{n-x}\\frac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}{B(\\alpha, \\beta)}d\\theta} \\\\\n& = \\frac{\\theta^{x+\\alpha-1}(1-\\theta)^{n-x+\\beta-1}}{\\int \\theta^{x+\\alpha-1}(1-\\theta)^{n-x+\\beta-1}d\\theta}\n\\end{align}\n\nSi recordamos la forma de la distribución Beta podemos ver que son muy similares y de hecho la distribución de probabilidad a posteriori es una distribución Beta con parámetros $\\alpha' = x+\\alpha$ y $\\beta' = n-x+\\beta$. Bravo!!!! Ya tenemos nuestra distribución de probabilidad a posteriori y sin realizar ninguna integral complicada.\n\n$$ P(\\theta|X) = \\frac{\\theta^{x+\\alpha-1}(1-\\theta)^{n-x+\\beta-1}}{B(x+\\alpha, n-x+\\beta)} $$\n\n$$ P(\\theta|X) \\sim Beta(x+\\alpha, n-x+\\beta) $$\n\nVamos a calcular la distribución de probabilidad a posteriori para los datos simulados.\n\n::: {#20a033ed .cell execution_count=4}\n``` {.python .cell-code}\nfrom scipy.stats import beta\n\nalpha_prior = 1\nbeta_prior = 1\n\nposterior = beta.pdf(theta, sum(datos == 1) + alpha_prior, 40 - sum(datos == 1) + beta_prior)\n\nplt.plot(theta, posterior, color='green')\nplt.xlabel(r'$\\theta$', fontsize=15)\nplt.ylabel(r'$P(\\theta|X)$', fontsize=15)\n\nplt.title('Distribución de Probabilidad a Posteriori', fontsize=20, fontweight='bold')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_statistics_files/figure-html/cell-5-output-1.png){width=633 height=465}\n:::\n:::\n\n\nJuntemos todo en un solo gráfico.\n\n::: {#8781337d .cell execution_count=5}\n``` {.python .cell-code}\nplt.figure(figsize=(10, 6))\n\nplt.plot(theta, binom.pmf(sum(datos == 1), 40, theta), color='blue', label='Verosimilitud')\nplt.plot(theta, beta.pdf(theta, alpha_prior, beta_prior), color='red', label='Priori')\nplt.plot(theta, posterior*0.185, color='green', label='Posteriori')\n\nplt.xlabel(r'$\\theta$', fontsize=15)\nplt.ylabel(r'$P(\\theta)$', fontsize=15)\nplt.title('Distribuciones de Probabilidad', fontsize=20, fontweight='bold')\n\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_statistics_files/figure-html/cell-6-output-1.png){width=819 height=539}\n:::\n:::\n\n\nSolamente escalamos la distribución a posteriori por fines de visualización. La distribución de probabilidad a posteriori es una combinación de la distribución de probabilidad a priori y la función de verosimilitud. La distribución de probabilidad a posteriori se concentra en valores de $\\theta$ que son consistentes con los datos observados y las creencias previas sobre el parámetro $\\theta$.\n\nEn este ejemplo hemos hecho uso de lo que se conocen como **priors conjugados**, que son aquellos que al multiplicar la función de verosimilitud por la distribución de probabilidad a priori, obtenemos una distribución de probabilidad a posteriori de la misma familia que la distribución de probabilidad a priori. En este caso, la distribución Beta es un prior conjugado para la distribución de Bernoulli o Binomial conocido como ***Modelo Beta-Binomial***. Algunos priors conjugados son:\n\n| Distribución de Probabilidad | Prior Conjugado | Posterior Conjugado |\n|------------------------------|-----------------|---------------------|\n| Bernoulli                    | Beta            | Beta                |\n| Binomial                     | Beta            | Beta                |\n| Poisson                      | Gamma           | Gamma               |\n| Normal                       | Normal          | Normal              |\n\n## Paso 4: Resumir la Distribución de Probabilidad a Posteriori\n\nUna vez que hemos calculado la distribución de probabilidad a posteriori de los parámetros $\\theta$ dado los datos $X$, podemos realizar inferencias sobre los parámetros del modelo. Por ejemplo, podemos calcular la media, la mediana, la moda y los intervalos de credibilidad de la distribución de probabilidad a posteriori.\n\n::: {#04cd1fc5 .cell execution_count=6}\n``` {.python .cell-code}\nfrom scipy.stats import beta\n\nmedia_posterior = beta.mean(sum(datos == 1) + alpha_prior, 40 - sum(datos == 1) + beta_prior)\nmediana_posterior = beta.median(sum(datos == 1) + alpha_prior, 40 - sum(datos == 1) + beta_prior)\nmoda_posterior = (sum(datos == 1) + alpha_prior - 1) / (40 + alpha_prior + beta_prior - 2)\n\ncredibilidad_95 = beta.interval(0.95, sum(datos == 1) + alpha_prior, 40 - sum(datos == 1) + beta_prior)\n\nprint(f'Media de la distribución de probabilidad a posteriori: {media_posterior:.2f}')\nprint(f'Mediana de la distribución de probabilidad a posteriori: {mediana_posterior:.2f}')\nprint(f'Moda de la distribución de probabilidad a posteriori: {moda_posterior:.2f}')\nprint(f'Intervalo de credibilidad al 95%: {credibilidad_95}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMedia de la distribución de probabilidad a posteriori: 0.64\nMediana de la distribución de probabilidad a posteriori: 0.65\nModa de la distribución de probabilidad a posteriori: 0.65\nIntervalo de credibilidad al 95%: (0.49405252639426683, 0.7787721379389346)\n```\n:::\n:::\n\n\nGráfiquemos la distribución de probabilidad a posteriori con la media y los intervalos de credibilidad.\n\n::: {#ef78134a .cell execution_count=7}\n``` {.python .cell-code}\nplt.plot(theta, posterior, color='green')\nplt.axvline(media_posterior, color='red', linestyle='--', label='Media')\nplt.fill_between(theta, 0, posterior, \n                where=(theta >= credibilidad_95[0]) & (theta <= credibilidad_95[1]), \n                color='green', alpha=0.25, \n                label='Intervalo de Credibilidad al 95%')\n\nplt.annotate(f'Mean: {media_posterior:.2f}', (media_posterior, 0), \n            textcoords='offset points', xytext=(0, 10), \n            ha='center', fontsize=12, color='black')\n\nplt.xlabel(r'$\\theta$', fontsize=15)\nplt.ylabel(r'$P(\\theta|X)$', fontsize=15)\nplt.title('Distribución de Probabilidad a Posteriori', fontsize=20, fontweight='bold')\n\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_statistics_files/figure-html/cell-8-output-1.png){width=633 height=465}\n:::\n:::\n\n\nEstos estadísticos son los que se reportan en la estadística bayesiana para resumir la distribución de probabilidad a posteriori y realizar inferencias sobre los parámetros del modelo. La media de la distribución de probabilidad a posteriori es un estimador puntual del parámetro $\\theta$ y representa el valor esperado de $\\theta$ dado los datos observados. La mediana de la distribución de probabilidad a posteriori es el valor que divide la distribución en dos partes iguales y representa el valor más probable de $\\theta$ dado los datos observados. La moda de la distribución de probabilidad a posteriori es el valor que tiene la mayor densidad de probabilidad y representa el valor más probable de $\\theta$ dado los datos observados. Los intervalos de credibilidad son intervalos que contienen un cierto porcentaje de la distribución de probabilidad a posteriori y representan la incertidumbre en la estimación de $\\theta$ dado los datos observados.\n\n# Algoritmos MCMC\n\nEn la práctica, calcular la distribución de probabilidad a posteriori de los parámetros $\\theta$ dado los datos $X$ puede ser complicado, especialmente cuando el modelo es complejo y no se puede obtener una solución analítica. En estos casos, se utilizan algoritmos de muestreo de Markov Chain Monte Carlo (MCMC) para aproximar la distribución de probabilidad a posteriori.\n\nVamos a despedazar el nombre del algoritmo:\n\n- **Markov Chain**: Es un proceso estocástico en el que la probabilidad de pasar de un estado a otro depende solo del estado actual y no de los estados anteriores. En el contexto de MCMC, la cadena de Markov es una secuencia de muestras de los parámetros $\\theta$ que se generan de acuerdo con la distribución de probabilidad a posteriori.\n- **Monte Carlo**: Es un método de simulación que se utiliza para aproximar la distribución de probabilidad a posteriori mediante la generación de muestras aleatorias de los parámetros $\\theta$.\n\n### Cadenas de Markov\n\nUna cadena de Markov es una secuencia de variables aleatorias $X_1, X_2, ..., X_n$ que satisfacen la propiedad de Markov. La propiedad de Markov establece que la probabilidad de que la variable aleatoria $X_{n+1}$ tome un valor dado depende solo del valor actual de la variable aleatoria $X_n$ y no de los valores anteriores de la variable aleatoria $X_1, X_2, ..., X_{n-1}$. En otras palabras, la probabilidad de transición de un estado a otro depende solo del estado actual y no de los estados anteriores.\n\nNormalmente se representan las cadenas de Markov mediante una matriz de transición $P$, que es una matriz cuadrada cuyas filas y columnas representan los estados de la cadena de Markov y cuyos elementos representan las probabilidades de transición de un estado a otro. \n\nVeamos un ejemplo de una cadena de Markov con dos estados.\n\n::: {#eaac6870 .cell execution_count=8}\n``` {.python .cell-code}\nimport numpy as np\n\nnp.random.seed(101408)\n\n# Matriz de transición\nP = np.array([[0.6, 0.4], [0.3, 0.7]])\n\n# Estado inicial\nestado = 0\n\n# Número de pasos\nn = 10\n\n# Generar la cadena de Markov\ncadena = [estado]\n\nfor i in range(n):\n    estado = np.random.choice([0, 1], p=P[estado])\n    cadena.append(estado)\n\ncadena\n```\n\n::: {.cell-output .cell-output-display execution_count=530}\n```\n[0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1]\n```\n:::\n:::\n\n\nEn este ejemplo, la cadena de Markov tiene dos estados (0 y 1) y la matriz de transición $P$ es una matriz de $2 \\times 2$ cuyos elementos representan las probabilidades de transición de un estado a otro. El estado inicial de la cadena de Markov es 0 y se generan 10 pasos de la cadena de Markov. La cadena de Markov es una secuencia de estados que se generan de acuerdo con la matriz de transición $P$.\n\nSi multiplicamos $n$ veces la matriz de transición $P$ por el vector de estado inicial, obtendremos la distribución de probabilidad de los estados de la cadena de Markov después de $n$ pasos.\n\n::: {#3e946685 .cell execution_count=9}\n``` {.python .cell-code}\nestado_inicial = np.array([1, 0])\n\nfor i in range(n):\n    estado_inicial = np.dot(estado_inicial, P)\n\nestado_inicial\n```\n\n::: {.cell-output .cell-output-display execution_count=531}\n```\narray([0.4285748, 0.5714252])\n```\n:::\n:::\n\n\nAquí se imprime la probabilidad de estar en el estado 0 y en el estado 1 después de 10 pasos de la cadena de Markov. La probabilidad de estar en el estado 0 es 0.428 y la probabilidad de estar en el estado 1 es 0.572.\n\nEn el caso de los algorithmos MCMC, la matriz de transición $P$ es una matriz de transición de la cadena de Markov que se utiliza para generar muestras de los parámetros $\\theta$ de acuerdo con el producto de la función de verosimilitud y la distribución de probabilidad a priori.\n\n### Monte Carlo\n\nEl método de Monte Carlo es un método de simulación que se utiliza para aproximar la distribución de probabilidad a posteriori mediante la generación de muestras aleatorias de los parámetros $\\theta$. El método de Monte Carlo se basa en el principio de que si se generan suficientes muestras aleatorias de los parámetros $\\theta$ de acuerdo con la distribución de probabilidad a posteriori, se puede aproximar la distribución de probabilidad a posteriori y realizar inferencias sobre los parámetros del modelo.\n\nUn ejemplo clásico de Monte Carlo es calcular el área de un círculo mediante la generación de puntos aleatorios dentro de un cuadrado que contiene el círculo y contando el número de puntos que caen dentro del círculo. La proporción de puntos que caen dentro del círculo con respecto al total de puntos generados es una aproximación del área del círculo.\n\n::: {#5e68ddc3 .cell execution_count=10}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(20011408)\n\nn = 2500\nx = np.random.uniform(-1, 1, n)\ny = np.random.uniform(-1, 1, n)\n\ndef dentro_circulo(x, y):\n    return x**2 + y**2 <= 1\n\nplt.figure(figsize=(6, 6))\nplt.scatter(x, y, c=dentro_circulo(x, y), cmap='coolwarm', s=10)\nplt.title('Puntos Aleatorios en un Círculo', fontsize=20, fontweight='bold')\nplt.axis('equal')\nplt.show()\n\narea_circulo = sum(dentro_circulo(x, y)) / n * 4\narea_circulo\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_statistics_files/figure-html/cell-11-output-1.png){width=530 height=514}\n:::\n\n::: {.cell-output .cell-output-display execution_count=532}\n```\n3.1328\n```\n:::\n:::\n\n\nEn este ejemplo, se generan 2500 puntos aleatorios dentro de un cuadrado que contiene un círculo de radio 1. Se cuentan el número de puntos que caen dentro del círculo y se calcula la proporción de puntos que caen dentro del círculo con respecto al total de puntos generados. La proporción de puntos que caen dentro del círculo es una aproximación del área del círculo y se multiplica por 4 para obtener el área del círculo.\n\nLos métodos Monte Carlo siguen un patrón en la resolución de problemas:\n\n1. Definir un conjunto posible de valores.\n2. Generar valores aleatorios de acuerdo a una distribución de probabilidad.\n3. Realizar un computo con los valores generados.\n4. Repetir los pasos 2 y 3 un número suficiente de veces.\n\n### Algoritmo Hastings-Metropolis\n\nEl algoritmo de Metropolis-Hastings es un algoritmo de muestreo de Markov Chain Monte Carlo (MCMC) que se utiliza para aproximar la distribución de probabilidad a posteriori de los parámetros $\\theta$ dado los datos $X$. El algoritmo de Metropolis-Hastings se basa en la generación de muestras de los parámetros $\\theta$ de acuerdo con la distribución de probabilidad a posteriori mediante la aceptación o rechazo de las muestras generadas.\n\nVeamos como funciona este algoritmo con un ejemplo sencillo. Supongamos que somos politicos y queremos que la mayoria de personas voten por nosotros. Supongamos que hay 7 estados, nuestro objetivo es visitar cada uno dependiendo de la población de cada estado. La probabilidad de visitar cada estado es proporcional a la población de cada estado. Supongamos que la población de cada estado es la siguiente:\n\n::: {#07388f62 .cell execution_count=11}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\npoblacion = np.array([100, 200, 300, 400, 500, 600, 700])\n\nproporcion = poblacion / sum(poblacion)\n\nplt.bar(range(1, 8), proporcion, color='blue')\nplt.xlabel('Estado', fontsize=15)\nplt.ylabel('Proporción', fontsize=15)\nplt.title('Proporción de Población por Estado', fontsize=20, fontweight='bold')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_statistics_files/figure-html/cell-12-output-1.png){width=614 height=466}\n:::\n:::\n\n\nEn este ejemplo, la población de cada estado es proporcional a la probabilidad de visitar cada estado. El objetivo es visitar cada estado de acuerdo con la proporción de la población de cada estado.\n\nDefinamos una regla para visitar cada estado. La regla es la siguiente:\n\n1. Elegir el primer estado a visitar de forma aleatoria.\n2. Pomos cambiarnos a cualquier estado aledaño.\n3. Para saber a que estado aledaño cambiarnos lanzamos una moneda y si cae cara consideramos el estado aledaño, si cae cruz consideramos el otro estado.\n4. Si la proporción de la población del estado considerado es mayor que la proporción de la población del estado actual, nos cambiamos al estado considerado. En caso contrario, giramos una ruleta y si cae en un número menor a la proporción de la población del estado considerado, nos cambiamos al estado considerado, sino nos quedamos en el estado actual.\n\nVeamos como se ve este algoritmo.\n\n::: {#2aa124c7 .cell execution_count=12}\n``` {.python .cell-code}\nnp.random.seed(20011408)\n\nn = 1000\nestados = np.zeros(n, dtype=int)\nestados[0] = np.random.choice(range(7))\n\nhab_act = poblacion[estados[0]]\npos_act = estados[0]\n\nfor i in range(1, n):\n    next_pos = pos_act + np.random.choice([-1, 1], p=[0.5, 0.5])\n    if next_pos > -1 and next_pos < 7:\n        hab_sig = poblacion[next_pos]\n        if hab_sig > hab_act:\n            estados[i] = next_pos\n            hab_act = hab_sig\n            pos_act = next_pos\n        else:\n            if np.random.rand() < hab_sig / hab_act:\n                estados[i] = next_pos\n                hab_act = hab_sig\n                pos_act = next_pos\n            else:\n                estados[i] = pos_act\n    else:\n        estados[i] = pos_act\n\n# Plor estados en eje x y la iteración en el eje y\nf, ax = plt.subplots(figsize=(10, 6))\nax.plot(estados, color='blue', ls='-', lw=1)\n\nplt.xlabel('Iteración', fontsize=15)\nplt.ylabel('Estado', fontsize=15)\nplt.title('Cadena de Markov', fontsize=20, fontweight='bold')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_statistics_files/figure-html/cell-13-output-1.png){width=806 height=539}\n:::\n:::\n\n\nVamos a crear un histograma de la densidad de visitas por estado y la verdadera proporción de la población de cada estado.\n\n::: {#098d7661 .cell execution_count=13}\n``` {.python .cell-code}\nplt.bar(range(0, 7), proporcion, color='red', alpha=0.25)\nplt.hist(estados, bins=7, color='blue', edgecolor='black', density=True, alpha=0.4)\nplt.xlabel('Estado', fontsize=15)\nplt.ylabel('Densidad', fontsize=15)\nplt.title('Frecuencia de Visitas por Estado', fontsize=20, fontweight='bold')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_statistics_files/figure-html/cell-14-output-1.png){width=604 height=465}\n:::\n:::\n\n\nComo vemos la cadena de Markov se ajusta a la proporción de la población de cada estado. Este es un ejemplo sencillo de como funciona el algoritmo de Metropolis-Hastings.\n\nEn general lo que hace el algoritmo de Metropolis-Hasting es lo siguiente:\n\n1. Inicializar el parámetro $\\theta$ con un valor inicial.\n2. Generar un valor propuesto $\\theta'$ de acuerdo a una distribución de probabilidad de propuesta.\n3. Calcular la razón de aceptación $r = \\frac{P(\\theta'|X)}{P(\\theta|X)}$.\n4. Generar un número aleatorio $u$ de una distribución uniforme en el intervalo $[0, 1]$.\n5. Si $u < r$, aceptar el valor propuesto $\\theta'$ y actualizar el parámetro $\\theta$ con el valor propuesto $\\theta'$.\n6. Si $u \\geq r$, rechazar el valor propuesto $\\theta'$ y mantener el parámetro $\\theta$ con el valor actual.\n7. Repetir los pasos 2-6 un número suficiente de veces para generar muestras de los parámetros $\\theta$ de acuerdo con la distribución de probabilidad a posteriori.\n\nLa *distribución propuesta* generalmente es una distribución normal con media en el valor actual del parámetro $\\theta$ y una desviación estándar que se ajusta para que la proporción de aceptación sea cercana al 0.5, pero se prefiere el uso de distribuciones no simricas alrededor del valor actual del parámetro $\\theta$.\n\nPara calcular la razón, se usa el producto de la función de verosimilitud, la distribución a priori y la probabilidad de la distribución propuesta. La probabilidad de la distribución propuesta se cancela en el cálculo de la razón de aceptación si es simétrica.\n\n$$ r = \\frac{P(X|\\theta')P(\\theta')}{P(X|\\theta)P(\\theta)} $$\n\nUna implementación sencilla del algoritmo de Metropolis-Hastings se encuentra [aquí](https://drive.google.com/file/d/1pL5qiH-Cn-TOzQQh5IO6pbZB-C3g4bcC/view?usp=sharing)\n\n\n# Software para Estadística Bayesiana\n\nExisten varios paquetes de software que se utilizan para realizar análisis estadísticos bayesianos que implementan algoritmos MCMC para aproximar la distribución de probabilidad a posteriori de los parámetros $\\theta$ dado los datos $X. Algunos de los paquetes de software más populares para realizar análisis estadísticos bayesianos son:\n\n- **Stan**\n- **PyMC3**\n- **JAGS**\n\nEstos paquetes de software proporcionan una interfaz de programación para especificar modelos estadísticos bayesianos y realizar inferencias sobre los parámetros del modelo utilizando algoritmos MCMC. Los paquetes de software también proporcionan herramientas para visualizar los resultados del análisis estadístico bayesiano y realizar diagnósticos de los algoritmos MCMC.\n\n## Stan\n\nStan es el lenguaje probabilístico más popular para realizar análisis estadísticos bayesianos, con el uso de algoritmos MCMC. Stan proporciona una interfaz de programación en C++, Python y R para especificar modelos estadísticos bayesianos y realizar inferencias sobre los parámetros del modelo.\n\nPara usarlo en python, se puede instalar con el siguiente comando:\n\n```bash\npip install pystan\n```\n\nPero solo funciona para sistemas operativos Unix (Linux, MacOS) y no para Windows. Se puede utilziar en google colab o en un servidor de jupyter notebook en un sistema operativo Unix.\n\nVeamos como realizar una regresión lineal bayesiana con Stan.\n\n::: {#0f3fbdaf .cell execution_count=14}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport stan\n\nnp.random.seed(20011408)\n\n# Generar datos\nn = 100\nx = np.random.normal(100, 25, n)\n\n# Coeficientes\nbeta_0 = 5\nbeta_1 = 2\n\n# Generar datos\ny = beta_0 + beta_1 * x + np.random.normal(0, 40, n)\n\nplt.scatter(x, y, color='blue')\nplt.xlabel('X', fontsize=15)\nplt.ylabel('Y', fontsize=15)\nplt.title('Datos simulados', fontsize=20, fontweight='bold')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_statistics_files/figure-html/cell-15-output-1.png){width=600 height=465}\n:::\n:::\n\n\nPara poder usar Stan, se debe de escribir un archivo con extensión `.stan` con el siguiente contenido:\n\n```stan\ndata {\n    int<lower=0> N;\n    vector[N] x;\n    vector[N] y;\n}\n\nparameters {\n    real beta_0;\n    real beta_1;\n    real<lower=0> sigma;\n}\n\nmodel {\n    beta_0 ~ normal(0, 10);\n    beta_1 ~ normal(0, 10);\n    sigma ~ normal(0, 10);\n    y ~ normal(beta_0 + beta_1 * x, sigma);\n}\n```\n\nEstos bloques se especifican de la siguiente manera:\n\n- **data**: Se especifican los datos que se utilizarán en el modelo. En este caso, se especifica el número de observaciones `N`, el vector de variables independientes `x` y el vector de variables dependientes `y`.\n- **parameters**: Se especifican los parámetros del modelo que se estimarán. En este caso, se especifican los coeficientes `beta_0` y `beta_1` de la regresión lineal y la desviación estándar `sigma` del error.\n- **model**: Se especifica el modelo estadístico que se utilizará para realizar inferencias sobre los parámetros del modelo. En este caso, se especifica que los datos `y` se distribuyen normalmente con media `beta_0 + beta_1 * x` y desviación estándar `sigma`.\n\nAhora vamos a compilar el modelo y ajustarlo a los datos.\n\n::: {#98dc4f5e .cell execution_count=15}\n``` {.python .cell-code}\nimport nest_asyncio\nnest_asyncio.apply()\nmodel = \"\"\"\ndata {\n    int<lower=0> N;\n    vector[N] x;\n    vector[N] y;\n}\n\nparameters {\n    real beta_0;\n    real beta_1;\n    real<lower=0> sigma;\n}\n\nmodel {\n    beta_0 ~ normal(0, 10);\n    beta_1 ~ normal(0, 10);\n    sigma ~ normal(0, 10);\n    y ~ normal(beta_0 + beta_1 * x, sigma);\n}\n\"\"\"\n\ndata_dict = {'N': n, 'x': x, 'y': y}\n\nposterior = stan.build(model, data=data_dict)\nfit = posterior.sample(num_chains=4, num_samples=2500, num_warmup=500)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBuilding...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nBuilding: found in cache, done.Sampling:   0%\nSampling:  25% (3000/12000)\nSampling:  50% (6000/12000)\nSampling:  75% (9000/12000)\nSampling: 100% (12000/12000)\nSampling: 100% (12000/12000), done.\nMessages received during sampling:\n  Gradient evaluation took 1.3e-05 seconds\n  1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.\n  Adjust your expectations accordingly!\n  Gradient evaluation took 5e-06 seconds\n  1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.\n  Adjust your expectations accordingly!\n  Gradient evaluation took 1e-05 seconds\n  1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.\n  Adjust your expectations accordingly!\n  Gradient evaluation took 6e-06 seconds\n  1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.\n  Adjust your expectations accordingly!\n```\n:::\n:::\n\n\nEl método `sampling` se utiliza para ajustar el modelo a los datos y realizar inferencias sobre los parámetros del modelo. El método `sampling` toma como argumento los datos que se utilizarán en el modelo y el número de iteraciones y cadenas que se utilizarán en el algoritmo MCMC.\n\n::: {#2a5aa265 .cell execution_count=16}\n``` {.python .cell-code}\ndf_fit = fit.to_frame()\ndf_fit.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=538}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>parameters</th>\n      <th>lp__</th>\n      <th>accept_stat__</th>\n      <th>stepsize__</th>\n      <th>treedepth__</th>\n      <th>n_leapfrog__</th>\n      <th>divergent__</th>\n      <th>energy__</th>\n      <th>beta_0</th>\n      <th>beta_1</th>\n      <th>sigma</th>\n    </tr>\n    <tr>\n      <th>draws</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-425.790441</td>\n      <td>0.998576</td>\n      <td>0.318289</td>\n      <td>3.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>426.414575</td>\n      <td>-5.135882</td>\n      <td>2.114701</td>\n      <td>40.687877</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-425.799625</td>\n      <td>0.950533</td>\n      <td>0.275060</td>\n      <td>3.0</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>426.205792</td>\n      <td>12.608344</td>\n      <td>1.963094</td>\n      <td>39.512798</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-425.340789</td>\n      <td>0.846835</td>\n      <td>0.275967</td>\n      <td>4.0</td>\n      <td>31.0</td>\n      <td>0.0</td>\n      <td>426.957590</td>\n      <td>10.653358</td>\n      <td>1.958102</td>\n      <td>37.124869</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-426.128923</td>\n      <td>0.992620</td>\n      <td>0.384027</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>426.135185</td>\n      <td>16.425698</td>\n      <td>1.910623</td>\n      <td>37.761391</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-426.743494</td>\n      <td>0.878910</td>\n      <td>0.318289</td>\n      <td>3.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>426.909396</td>\n      <td>-2.360512</td>\n      <td>2.134145</td>\n      <td>41.332574</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nPara visualizar los resultados del análisis estadístico bayesiano, se puede convertir el objeto `fit` en un `DataFrame` de `pandas` y visualizar los resultados del análisis estadístico bayesiano. O podemos usar la libreria `arviz` para visualizar los resultados.\n\n::: {#b7e6d53c .cell execution_count=17}\n``` {.python .cell-code}\nimport arviz as az\n\naz.plot_trace(fit, var_names=['beta_0', 'beta_1', 'sigma'], figsize=(10, 10), combined=True)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_statistics_files/figure-html/cell-18-output-1.png){width=767 height=800}\n:::\n:::\n\n\nOtros gráficos que se pueden hacer son:\n\n::: {#9a87d515 .cell execution_count=18}\n``` {.python .cell-code}\naz.plot_posterior(fit, var_names=['beta_0', 'beta_1', 'sigma'], figsize=(12, 4), kind='kde', hdi_prob=0.95)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_statistics_files/figure-html/cell-19-output-1.png){width=916 height=367}\n:::\n:::\n\n\n::: {#976f4cc8 .cell execution_count=19}\n``` {.python .cell-code}\naz.plot_forest(fit, var_names=['beta_0', 'beta_1'], figsize=(12, 4), hdi_prob=0.95, r_hat=True, ess = True)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_statistics_files/figure-html/cell-20-output-1.png){width=985 height=367}\n:::\n:::\n\n\n::: {#e6ded0af .cell execution_count=20}\n``` {.python .cell-code}\naz.plot_pair(fit, var_names=['beta_0', 'beta_1'], figsize=(12, 8), kind='kde', marginals=True)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](bayesian_statistics_files/figure-html/cell-21-output-1.png){width=1009 height=688}\n:::\n:::\n\n\nEstos gráficos proporcionan información sobre la distribución de probabilidad a posteriori de los parámetros del modelo y permiten realizar inferencias sobre los parámetros del modelo. Por ejemplo, el gráfico de traza muestra la traza de las cadenas de Markov para los parámetros del modelo y permite evaluar la convergencia de las cadenas de Markov. El gráfico de densidad muestra la distribución de probabilidad a posteriori de los parámetros del modelo y permite visualizar la incertidumbre en la estimación de los parámetros del modelo. El gráfico de bosque muestra la distribución de probabilidad a posteriori de los parámetros del modelo y permite comparar los parámetros del modelo entre sí. El gráfico de pares muestra la relación entre los parámetros del modelo y permite visualizar la correlación entre los parámetros del modelo.\n\n",
    "supporting": [
      "bayesian_statistics_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}