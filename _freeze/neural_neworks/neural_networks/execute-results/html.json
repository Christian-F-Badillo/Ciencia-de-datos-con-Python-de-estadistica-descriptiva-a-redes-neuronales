{
  "hash": "9712a947e2326d15d781983c1a6caaab",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Introducción a Redes Neuronales\"\nauthor: \"Christian Badillo\"\nformat: html\ndate: today\norder: 2\n---\n\n# Redes Neuronales Artificiales\n\nLas redes neuronales artificiales son un modelo computacional inspirado en el cerebro humano. Están compuestas por nodos llamados neuronas que están conectados entre sí. Cada conexión entre neuronas tiene un peso asociado que se ajusta durante el entrenamiento del modelo. Estos pesos son los parámetros que se ajustan para que el modelo pueda realizar predicciones, es decir, son la memoria del modelo y representan la importancia de cada conexión.\n\nLas redes neuronales artificiales se dividen en capas, cada capa está compuesta por un conjunto de neuronas. La primera capa se llama **capa de entrada**, la última capa se llama **capa de salida** y las capas intermedias se llaman **capas ocultas**. La capa de entrada recibe los datos de entrada, la capa de salida produce la predicción y las capas ocultas procesan la información.\n\n![Red Neuronal](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Artificial_neural_network.svg/500px-Artificial_neural_network.svg.png)\n\n## Comportamiento de una Neurona\n\nCada neurona recibe una serie de entradas, las multiplica por los pesos asociados a cada conexión y aplica una función de activación. La **función de activación** es una función no lineal que se encarga de introducir no linealidades en el modelo. \n\nMatemáticamente, el comportamiento de una neurona se puede expresar de la siguiente forma:\n\n$$y = f(\\sum_{i=1}^{n} x_i \\cdot w_i + b)$$\n\nDonde $x_i$ son las entradas, $w_i$ son los pesos asociados a cada conexión, $b$ es el sesgo y $f$ es la función de activación. Si usaramos una función de activación lineal, la red neuronal sería equivalente a un modelo de regresión lineal. \n\nEntonces podemos usar una red neuronal para regresión lineal:\n\n\\begin{align*}\ny &= f(\\sum_{i=1}^{n} x_i \\cdot w_i + b) \\hspace{1cm} \\text{Donde } f(x) = x \\\\\ny &= \\sum_{i=1}^{n} x_i \\cdot w_i + b\n\\end{align*}\n\nExisten diversas funciones de activación, algunas de las más comunes son:\n\n- **Función Sigmoide**.\n  $$f(x) = \\frac{1}{1 + e^{-x}}$$\n  \n- **Función ReLU**.\n  $$f(x) = \\max(0, x)$$\n\n- **Función Tangente Hiperbólica**.\n    $$f(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$$\n\n- **Función Softmax**.\n    $$f(x) = \\frac{e^x}{\\sum_{i=1}^{n} e^{x_i}}$$\n\n- **Función de Identidad**.\n    $$f(x) = x$$\n\nCada función de activación tiene sus propias características y se utiliza en diferentes contextos. Por ejemplo, la función sigmoide se utiliza en la capa de salida de una red neuronal para clasificación binaria, la función ReLU se utiliza en las capas ocultas y la función softmax se utiliza en la capa de salida para clasificación multiclase.\n\nVisualicemos el comportamiento de algunas funciones de activación:\n\n::: {#12aba922 .cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(2, 2, figsize=(8, 4), sharex=True)\n\nx = np.linspace(-5, 5, 100)\n\n# Funciones de activación\nsigmoid = 1 / (1 + np.exp(-x))\nrelu = np.maximum(0, x)\ntanh = np.tanh(x)\nsoftmax = np.exp(x) / np.sum(np.exp(x))\n\n# Gráficas\nax[0, 0].plot(x, sigmoid)\nax[0, 0].set_title(\"Función Sigmoide\")\n\nax[0, 1].plot(x, relu)\nax[0, 1].set_title(\"Función ReLU\")\n\nax[1, 0].plot(x, tanh)\nax[1, 0].set_title(\"Función Tangente Hiperbólica\")\n\nax[1, 1].plot(x, softmax)\nax[1, 1].set_title(\"Función Softmax\")\n\nfor i in range(2):\n    for j in range(2):\n        ax[i, j].grid( linestyle='--', linewidth=0.5, alpha=0.5, color='grey')\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](neural_networks_files/figure-html/cell-2-output-1.png){width=758 height=374}\n:::\n:::\n\n\nHagamos lo que hace una neurona con una función de activación sigmoide.\n\n::: {#38b393ef .cell execution_count=3}\n``` {.python .cell-code}\n# Función de activación sigmoide\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\n# Datos de entrada\nX = np.random.randn(10, 1)\n\n# Pesos y sesgo\nnp.random.seed(1014)\nweights = np.random.randn(1, 10)\nbias = np.random.randn(1)\n\n# Salida de la neurona\ny = sigmoid(np.dot(X.T, weights.T) + bias)\n\nprint(y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[0.20899694]]\n```\n:::\n:::\n\n\nEstamos realizando la siguiente operación:\n\n$$y = f(\\sum_{i=1}^{n} x_i \\cdot w_i + b)$$\n\nDonde $f(x) = \\frac{1}{1 + e^{-x}}$ es la función sigmoide. En este caso, estamos utilizando una neurona con 10 entradas y una salida.\n\nLo que busca simular o modelar el comportamiento de una neurona biológica. La neurona biológica recibe señales eléctricas de otras neuronas a través de las dendritas, las procesa en el cuerpo celular y envía una señal eléctrica a través del axón. La señal eléctrica se transmite a través de las sinapsis, que son las conexiones entre las neuronas.\n\nAhora veamos cómo se comporta una red neuronal con una capa oculta y una capa de salida. Para esto, vamos a implementar una red neuronal para regresión lineal con pesos y sesgos aleatorios.\n\n::: {#c41cd381 .cell execution_count=4}\n``` {.python .cell-code}\nimport numpy as np\n\nclass NeuralNetwork():\n    def __init__(self, input_size, hidden_size, output_size, seed=1014):\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        \n        # Pesos y sesgos\n        np.random.seed(seed)\n        self.weights_input_hidden = np.random.randn(input_size, hidden_size)\n        self.bias_input_hidden = np.random.randn(hidden_size)\n        \n        self.weights_hidden_output = np.random.randn(hidden_size, output_size)\n        self.bias_hidden_output = np.random.randn(output_size)\n        \n    def forward(self, X, activation):\n        # Capa oculta\n        hidden = np.dot(X, self.weights_input_hidden) + self.bias_input_hidden\n        hidden = activation(hidden)\n        \n        # Capa de salida\n        output = np.dot(hidden, self.weights_hidden_output) + self.bias_hidden_output\n        \n        return output\n```\n:::\n\n\nUsemos la red neuronal para predecir un conjunto de datos y con una función de activación identidad.\n\n::: {#ef57ecfa .cell execution_count=5}\n``` {.python .cell-code}\n# Datos de entrada\nX = np.random.randn(10, 1)\n\n# Parámetros de la red neuronal\ninput_size = 1\nhidden_size = 10\noutput_size = 1\n\n# Red Neuronal\nnn = NeuralNetwork(input_size, hidden_size, output_size)\n\n# Función de activación identidad\ndef identity(x):\n    return x\n\n# Predicciones\ny_pred = nn.forward(X, identity)\n\nprint(y_pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[-1.81046445]\n [-1.98312314]\n [-1.86441218]\n [-2.03739283]\n [-1.77027647]\n [-1.92937854]\n [-1.87128124]\n [-1.94289359]\n [-2.20644573]\n [-1.93053922]]\n```\n:::\n:::\n\n\nEn este caso tenemos una red neuronal con una capa oculta de 10 neuronas y una capa de salida de 1 neurona. La función de activación de la capa oculta es la función identidad y la función de activación de la capa de salida también es la función identidad.\n\nLos pesos de la red son:\n\n::: {#fe30c2b7 .cell execution_count=6}\n``` {.python .cell-code}\nprint(f\"Pesos capa oculta: {nn.weights_input_hidden}\\n\")\nprint(f\"Sesgos capa oculta: {nn.bias_input_hidden}\\n\")\nprint(f\"Pesos capa de salida: {nn.weights_hidden_output.T}\\n\")\nprint(f\"Sesgos capa de salida: {nn.bias_hidden_output}\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPesos capa oculta: [[ 0.75943278 -1.00725987 -0.64499024 -0.26674068  0.29125552  0.14820587\n   0.6382988   0.46738854  0.53122954  1.1840206 ]]\n\nSesgos capa oculta: [-1.25173295 -1.30489407  0.20194032 -0.83407915  0.67556507 -1.65562438\n -0.26710189 -0.77413114 -0.14915279  2.15093091]\n\nPesos capa de salida: [[-0.25697236  0.50673502 -1.31687341  1.71747235 -0.12242967 -0.06419002\n   0.47479916 -0.01225672  1.10530347 -0.54019387]]\n\nSesgos capa de salida: [1.4985733]\n\n```\n:::\n:::\n\n\nPodemos dibujar la red neuronal con los pesos y sesgos asociados a cada conexión.\n\n::: {#5c680a47 .cell execution_count=7}\n``` {.python .cell-code}\nimport itertools\nimport matplotlib.pyplot as plt\nimport networkx as nx\n\n# Colores para las capas\nsubset_colors = ['blue', 'red', 'green']\n\ndef multilayered_graph(input_size, hidden_size, output_size, weights_input_hidden, weights_hidden_output):\n    # Crear los rangos para las capas\n    subset_sizes = [input_size, hidden_size, output_size]\n    extents = nx.utils.pairwise(itertools.accumulate((0,) + tuple(subset_sizes)))\n    layers = [range(start, end) for start, end in extents]\n    \n    # Crear el gráfico\n    G = nx.Graph()\n    for i, layer in enumerate(layers):\n        G.add_nodes_from(layer, layer=i)\n        \n    # Añadir los bordes con pesos para capa de entrada a oculta\n    for i, j in itertools.product(layers[0], layers[1]):\n        G.add_edge(i, j, weight=round(weights_input_hidden[i, j - layers[1][0]], 3))\n        \n    # Añadir los bordes con pesos para capa oculta a salida\n    for i, j in itertools.product(layers[1], layers[2]):\n        G.add_edge(i, j, weight=round(weights_hidden_output[i - layers[1][0], j - layers[2][0]], 3))\n    \n    return G\n\n# Crear el gráfico con los pesos\nG = multilayered_graph(input_size, hidden_size, output_size, nn.weights_input_hidden, nn.weights_hidden_output)\n\n# Colores para los nodos según su capa\ncolor = [subset_colors[data[\"layer\"]] for node, data in G.nodes(data=True)]\n\n# Posición de los nodos\npos = nx.multipartite_layout(G, subset_key=\"layer\")\n\n# Dibujar el gráfico\nplt.figure(figsize=(10, 6))\nnx.draw(G, pos, with_labels=False, node_color=color, node_size=1500, font_size=10, font_weight='bold')\n\n# Dibujar los bordes con los pesos\nedge_labels = nx.get_edge_attributes(G, 'weight')\nnx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=12)\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](neural_networks_files/figure-html/cell-7-output-1.png){width=979 height=595}\n:::\n:::\n\n\nCada una de las neuronas realiza la operación que hemos visto anteriormente. Sin embargo, aquí solo hemos decidido los pesos y sesgos de la red neuronal de forma aleatoria. En la práctica, estos pesos y sesgos se ajustan durante el entrenamiento de la red neuronal, es decir, la red neuronal aprende a partir de los datos.\n\n## Entrenamiento de una Red Neuronal\n\nEl entrenamiento de una red neuronal consiste en ajustar los pesos y sesgos de la red para minimizar una función de pérdida. La función de pérdida mide la diferencia entre las predicciones del modelo y los valores reales. Durante el entrenamiento, los pesos y sesgos se ajustan iterativamente utilizando un algoritmo de optimización.\n\nExisten diversos algoritmos de optimización, algunos de los más comunes son:\n\n- **Descenso del Gradiente** : Actualiza los pesos en la dirección opuesta al gradiente de la función de pérdida.\n- **Adam**: Utiliza una combinación de descenso del gradiente y adaptación de la tasa de aprendizaje.\n- **RMSprop**: Se adapta a la tasa de aprendizaje para cada parámetro.\n- **Adagrad**: Ajusta la tasa de aprendizaje para cada parámetro en función de la magnitud de los gradientes.\n\nEl algoritmo tipico es el descenso del gradiente. La idea es ajustar los pesos y sesgos de la red neuronal en la dirección opuesta al gradiente de la función de pérdida. El gradiente de la función de pérdida se calcula utilizando la regla de la cadena y el algoritmo de retropropagación. Pero en la práctica, se utiliza una variante del descenso del gradiente llamada **descenso del gradiente estocástico** o el algoritmo **Adam**.\n\nAlgunas funciones de pérdida comunes son:\n\n- **Error Cuadrático Medio**.\n  $$L(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n\n- **Entropía Cruzada**.\n    $$L(y, \\hat{y}) = -\\frac{1}{n} \\sum_{i=1}^{n} y_i \\log(\\hat{y}_i)$$\n\n- **Error Absoluto Medio**.\n    $$L(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$\n\nEl algoritmo de entrenamiento de una red neuronal se puede resumir en los siguientes pasos:\n\n1. Inicializar los pesos y sesgos de la red neuronal.\n2. Calcular la salida de la red neuronal.\n3. Calcular la función de pérdida.\n4. Calcular el gradiente de la función de pérdida.\n5. Actualizar los pesos y sesgos utilizando un algoritmo de optimización.\n6. Repetir los pasos 2-5 hasta que se alcance un número de iteraciones o se cumpla un criterio de parada.\n\n### Aprendizaje de pesos y sesgos en una neurona\n\nVamos a ver cómo se actualizan los pesos y sesgos de una neurona durante el entrenamiento. Para esto, vamos a implementar una neurona con una función de activación sigmoide y vamos a entrenar la neurona para realizar una regresión lineal y usar la función de pérdida de error cuadrático medio.\n\nPara obtener el gradiente de la función de pérdida, vamos a utilizar la regla de la cadena y el algoritmo de retropropagación. La regla de la cadena se utiliza para calcular el gradiente de una función compuesta y el algoritmo de retropropagación se utiliza para calcular el gradiente de la función de pérdida con respecto a los pesos y sesgos de la red neuronal.\n\n#### Regla de la Cadena para el Gradiente\n\nLa regla de la cadena se utiliza para calcular el gradiente de una función compuesta. Si tenemos una función $f(g(x))$, el gradiente de $f$ con respecto a $x$ se puede calcular como:\n\n$$\\frac{\\partial f(g(x))}{\\partial x} = \\frac{\\partial f(g(x))}{\\partial g(x)} \\cdot \\frac{\\partial g(x)}{\\partial x}$$\n\nEn nuestro caso tenemos una función de pérdida $L(y, \\hat{y})$ y una función de activación $f(x)$. Entonces, el gradiente de la función de pérdida con respecto a los pesos y sesgos de la red neuronal se puede calcular como:\n\n$$\\frac{\\partial L(y, \\hat{y})}{\\partial w_i} = \\frac{\\partial L(y, \\hat{y})}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial z} \\cdot \\frac{\\partial z}{\\partial w_i}$$\n\nDonde $z = \\sum_{i=1}^{n} x_i \\cdot w_i + b$ es la entrada de la neurona y $\\hat{y} = f(z)$ es la salida de la neurona.\n\nHagamos la primera parte de la regla de la cadena, es decir, el gradiente de la función de pérdida con respecto a la salida de la neurona.\n\n\\begin{align*}\n\\frac{\\partial L(y, \\hat{y})}{\\partial \\hat{y}} &= \\frac{\\partial}{\\partial \\hat{y}} \\left( \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 \\right) \\\\\n&= \\frac{1}{n} \\sum_{i=1}^{n} \\frac{\\partial}{\\partial \\hat{y}} (y_i - \\hat{y}_i)^2 \\\\\n&= \\frac{1}{n} \\sum_{i=1}^{n} -2(y_i - \\hat{y}_i) \\\\\n&= \\frac{-2}{n} \\sum_{i=1}^{n}(\\hat{y}_i - y_i)\n\\end{align*}\n\nLa segunda parte de la regla de la cadena es el gradiente de la salida de la neurona con respecto a la entrada de la neurona.\n\n\\begin{align*}\n\\frac{\\partial \\hat{y}}{\\partial z} &= \\frac{\\partial}{\\partial z} \\left( \\frac{1}{1 + e^{-z}} \\right) \\\\\n&= \\frac{e^{-z}}{(1 + e^{-z})^2} \\\\\n&= \\frac{1}{1 + e^{-z}} \\cdot \\left(1 - \\frac{1}{1 + e^{-z}} \\right) \\\\\n&= \\hat{y} \\cdot (1 - \\hat{y})\n\\end{align*}\n\nLa tercera parte de la regla de la cadena es el gradiente de la entrada de la neurona con respecto a los pesos.\n\n\\begin{align*}\n\\frac{\\partial z}{\\partial w_i} &= \\frac{\\partial}{\\partial w_i} \\left( \\sum_{i=1}^{n} x_i \\cdot w_i + b \\right) \\\\\n&= x_i\n\\end{align*}\n\nAhora para el sesgo.\n\n\\begin{align*}\n\\frac{\\partial z}{\\partial b} &= \\frac{\\partial}{\\partial b} \\left( \\sum_{i=1}^{n} x_i \\cdot w_i + b \\right) \\\\\n&= 1\n\\end{align*}\n\nEntonces, el gradiente de la función de pérdida con respecto a los pesos y sesgos de la red neuronal se puede calcular como:\n\n\\begin{align*}\n\\frac{\\partial L(y, \\hat{y})}{\\partial w_i} &= \\frac{-2}{n} \\sum_{i=1}^{n}(\\hat{y}_i - y_i) \\cdot \\hat{y}_i \\cdot (1 - \\hat{y}_i) \\cdot x_i \\\\\n\\frac{\\partial L(y, \\hat{y})}{\\partial b} &= \\frac{-2}{n} \\sum_{i=1}^{n}(\\hat{y}_i - y_i) \\cdot \\hat{y}_i \\cdot (1 - \\hat{y}_i)\n\\end{align*}\n\n##### Actualización de los pesos y sesgos\n\nPara actualizar los pesos y sesgos de la red neuronal, utilizamos el algoritmo de descenso del gradiente. La actualización de los pesos y sesgos se realiza de la siguiente forma:\n\n\\begin{align*}\nw_i &:= w_i - \\alpha \\cdot \\frac{\\partial L(y, \\hat{y})}{\\partial w_i} \\\\\nb &:= b - \\alpha \\cdot \\frac{\\partial L(y, \\hat{y})}{\\partial b}\n\\end{align*}\n\nDonde $\\alpha$ es la tasa de aprendizaje, que es un hiperparámetro del modelo. La tasa de aprendizaje controla la magnitud de la actualización de los pesos y sesgos. Si la tasa de aprendizaje es muy pequeña, el modelo puede tardar mucho tiempo en converger. Si la tasa de aprendizaje es muy grande, el modelo puede divergir.\n\n#### Retropropagación del Gradiente.\n\nLa retropropagación es un algoritmo que se utiliza para calcular el gradiente de la función de pérdida con respecto a los pesos y sesgos de la red neuronal, usamos la regla de la cadena para calcular el gradiente de la función de pérdida con respecto a los pesos y sesgos de la red neuronal y lo propagamos hacia atrás a través de la red neuronal.\n\nPara cada capa de la red neuronal, calculamos el gradiente de la función de pérdida con respecto a los pesos y sesgos de la capa utilizando la regla de la cadena y el gradiente de la capa anterior. Luego, actualizamos los pesos y sesgos de la capa. Este proceso se repite para todas las capas de la red neuronal. Un hermoso gif creado por [Michael Pyrcz](https://x.com/GeostatsGuy/status/1802719780282982832) muestra cómo funciona la retropropagación.\n\n![Retropropagación del Gradiente](/img/ann/backpropagation.gif){width=100%}\n\n### Implementación de Backpropagation\n\nHagamos una red neuronal con 1 neurona en la capa oculta y 5 neuronas en la capa de salida, usaremos la función de activación sigmoide para la capa oculta y la función de activación identidad para la capa de salida. Vamos a entrenar la red neuronal para realizar una regresión lineal y usaremos la función de pérdida de error cuadrático medio.\n\n#### Datos de Entrada\n\nSimulemos datos de entrada y salida para entrenar la red neuronal. \n\n::: {#735c93a9 .cell execution_count=8}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\n\n# Datos de entrada\nX = np.random.normal(0, 5, (40, 1))\n\n# Datos de salida\ny = 2 * X + 3 + np.random.normal(0, 1, (40, 1))\n\ndf = pd.DataFrame(np.concatenate([X, y], axis=1), columns=[\"X\", \"y\"])\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=86}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.705603</td>\n      <td>5.973504</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-6.149390</td>\n      <td>-8.670173</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.814690</td>\n      <td>13.924261</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.384975</td>\n      <td>6.429876</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.502252</td>\n      <td>2.931682</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n#### Funciones auxiliares\n\nVamos a implementar algunas funciones auxiliares para la red neuronal.\n\n::: {#6fd0273d .cell execution_count=9}\n``` {.python .cell-code code-fold=\"true\"}\n# Función de activación sigmoide\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\n# Función de pérdida de error cuadrático medio\ndef mse(y, y_pred):\n    return np.mean((y - y_pred) ** 2)\n\ndef weight_derivative_hidden(X, y, y_pred):\n    \"\"\"\n    Derivada de los pesos de la capa oculta\n    \"\"\"\n    return -2 * np.mean((y - y_pred) * y_pred * (1 - y_pred) * X)\n\ndef bias_derivative_hidden(y, y_pred):\n    \"\"\"\n    Derivada del sesgo de la capa oculta\n    \"\"\"\n    return -2 * np.mean((y - y_pred) * y_pred * (1 - y_pred))\n\ndef weight_derivative_output(hidden, y, y_pred):\n    \"\"\"\n    Derivada de los pesos de la capa de salida para la función de pérdida de error cuadrático medio y función de activación identidad\n    \"\"\"\n    return -2 * np.mean((y - y_pred) * X)\n\ndef bias_derivative_output(y, y_pred):\n    \"\"\"\n    Derivada del sesgo de la capa de salida para la función de pérdida de error cuadrático medio y función de activación identidad\n    \"\"\"\n    return -2 * np.mean(y - y_pred)\n\n# Inicialización de los pesos y sesgos\ndef initialize_weights(input_size, hidden_size, output_size, seed=1014):\n    np.random.seed(seed)\n    weights_input_hidden = np.random.randn(input_size, hidden_size)\n    bias_input_hidden = np.random.randn(hidden_size)\n    \n    weights_hidden_output = np.random.randn(hidden_size, output_size)\n    bias_hidden_output = np.random.randn(output_size)\n    \n    return weights_input_hidden, bias_input_hidden, weights_hidden_output, bias_hidden_output\n```\n:::\n\n\n#### Entrenamiento de la Red Neuronal\n\nVamos a entrenar la red neuronal utilizando el algoritmo de retropropagación. Durante el entrenamiento, vamos a calcular la función de pérdida, el gradiente de la función de pérdida con respecto a los pesos y sesgos de la red neuronal y vamos a actualizar los pesos y sesgos utilizando el algoritmo de descenso del gradiente.\n\n::: {#45388a56 .cell execution_count=10}\n``` {.python .cell-code}\ndef learning( X, y, weights_input_hidden, bias_input_hidden, weights_hidden_output, bias_hidden_output, learning_rate=0.01):\n    # Capa oculta\n    hidden = np.dot(X, weights_input_hidden) + bias_input_hidden\n    hidden = sigmoid(hidden)\n    \n    # Capa de salida\n    output = np.dot(hidden, weights_hidden_output) + bias_hidden_output\n    \n    # Función de pérdida\n    loss = mse(y, output)\n    \n    # Gradiente de la función de pérdida con respecto a los pesos y sesgos de la red neuronal\n    weight_der_hidden = weight_derivative_hidden(X, y, output)\n    bias_der_hidden = bias_derivative_hidden(y, output)\n    \n    weight_der_output = weight_derivative_output(hidden, y, output)\n    bias_der_output = bias_derivative_output(y, output)\n    \n    # Actualización de los pesos y sesgos\n    weights_input_hidden -= learning_rate * weight_der_hidden\n    bias_input_hidden -= learning_rate * bias_der_hidden\n    \n    weights_hidden_output -= learning_rate * weight_der_output\n    bias_hidden_output -= learning_rate * bias_der_output\n    \n    return weights_input_hidden, bias_input_hidden, weights_hidden_output, bias_hidden_output, loss\n\n# Creamos un bucle para entrenar la red neuronal\n\ninput_size = 1\nhidden_size = 5\noutput_size = 1\n\nweights_input_hidden, bias_input_hidden, weights_hidden_output, bias_hidden_output = initialize_weights(input_size, hidden_size, output_size)\n\nlearning_rate = 0.0001\nepochs = 1500\n\nX_normalized = (X - X.mean()) / X.std()\nY_normalized = (y - y.mean()) / y.std()\n\nfor epoch in range(epochs):\n    weights_input_hidden, bias_input_hidden, weights_hidden_output, bias_hidden_output, loss = learning(\n    X_normalized, Y_normalized, \n    weights_input_hidden, \n    bias_input_hidden, \n    weights_hidden_output, \n    bias_hidden_output, \n    learning_rate)\n    \n    if epoch % 100 == 0:\n        print(f\"Epoch {epoch}: Loss {loss}\")\n    elif epoch == epochs - 1:\n        print(f\"Epoch {epoch}: Loss {loss}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 0: Loss 9.962358063298385\nEpoch 100: Loss 6.389020521754107\nEpoch 200: Loss 4.640115312713357\nEpoch 300: Loss 3.593583112789311\nEpoch 400: Loss 2.893864014205564\nEpoch 500: Loss 2.4040869381649284\nEpoch 600: Loss 2.0676644655384124\nEpoch 700: Loss 1.8628933379595423\nEpoch 800: Loss 1.7838514284596045\nEpoch 900: Loss 1.830931639664496\nEpoch 1000: Loss 2.0075290899566314\nEpoch 1100: Loss 2.3237647638230507\nEpoch 1200: Loss 2.8109028707617965\nEpoch 1300: Loss 3.559636339546768\nEpoch 1400: Loss 4.8448697380727035\nEpoch 1499: Loss 7.692389417773325\n```\n:::\n:::\n\n\n### Predicciones de la Red Neuronal\n\nUna ves que hemos entrenado la red neuronal, podemos hacer predicciones con la red neuronal que es el objetivo de crear un modelo de aprendizaje automático.\n\n::: {#df8f2909 .cell execution_count=11}\n``` {.python .cell-code}\ndef predict(X, weights_input_hidden, bias_input_hidden, weights_hidden_output, bias_hidden_output):\n    hidden = np.dot(X, weights_input_hidden) + bias_input_hidden\n    hidden = sigmoid(hidden)\n    \n    output = np.dot(hidden, weights_hidden_output) + bias_hidden_output\n    \n    return output\n\ny_pred = predict(X_normalized, weights_input_hidden, bias_input_hidden, weights_hidden_output, bias_hidden_output)\n\ndf_normalized = pd.DataFrame(np.concatenate([X_normalized, Y_normalized, y_pred], axis=1), columns=[\"X\", \"y\", \"y_pred\"])\n\ndf_normalized.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=89}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X</th>\n      <th>y</th>\n      <th>y_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.223278</td>\n      <td>0.172289</td>\n      <td>1.025840</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.426558</td>\n      <td>-1.375204</td>\n      <td>3.560325</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.086337</td>\n      <td>1.012498</td>\n      <td>0.068435</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.365971</td>\n      <td>0.220517</td>\n      <td>0.829005</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.029469</td>\n      <td>-0.149160</td>\n      <td>1.409019</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nA nivel profesional, se utilizan librerías como TensorFlow, PyTorch o Keras para implementar redes neuronales. Estas librerías proporcionan una interfaz de alto nivel para construir y entrenar redes neuronales de forma eficiente. Sin embargo, es importante entender cómo funcionan las redes neuronales a nivel de bajo nivel para poder depurar y optimizar los modelos.\n\n# Otros tipos de Redes Neuronales\n\nHasta ahora hemos visto cómo funcionan las redes neuronales artificiales y cómo se entrenan utilizando el algoritmo de retropropagación. Sin embargo, existen otros tipos de redes neuronales que se utilizan para diferentes tareas de aprendizaje automático. Algunos de los tipos de redes neuronales más comunes son:\n\n- **Redes Neuronales Convolucionales (CNN)**: Se utilizan para tareas de visión por computadora, como clasificación de imágenes, detección de objetos y segmentación semántica.\n- **Redes Neuronales Recurrentes (RNN)**: Se utilizan para tareas de procesamiento de lenguaje natural, como traducción automática, generación de texto y análisis de sentimientos.\n- **Redes Neuronales Generativas Adversarias (GAN)**: Se utilizan para generar datos sintéticos, como imágenes, texto y audio.\n- **Transformers**: Se utilizan para tareas de procesamiento de lenguaje natural, como traducción automática, generación de texto y análisis de sentimientos.\n- **Encoders y Decoders**: Se utilizan para tareas de traducción automática, generación de texto y resumen de texto.\n\nCada tipo de red neuronal tiene sus propias características y se utiliza en diferentes contextos. Algunas redes son más sencillos de entrenar y otras son más complejas. Por ejemplo, las redes neuronales convolucionales son más sencillas de entrenar que las redes neuronales recurrentes, ya que las redes convolucionales no tienen dependencias temporales.\n\n",
    "supporting": [
      "neural_networks_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}