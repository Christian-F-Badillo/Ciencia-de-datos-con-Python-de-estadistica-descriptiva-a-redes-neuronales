---
title: "Manipulación de datos con Pandas"
author: "Christian Badillo"
format: html
date: today
order: 1
filters:
  - pyodide
  - fontawesome
  - iconify
---

# Bases de datos

Una base de datos es un conjunto de datos organizados y relacionados entre sí. Existen diferentes tipos de bases de datos, como las bases de datos relacionales y las bases de datos no relacionales. 

Las **bases de datos relacionales** son las más comunes y se basan en el modelo relacional, que organiza los datos en tablas. Cada tabla tiene filas y columnas, donde cada fila representa un registro y cada columna representa un campo. 

Las **bases de datos no relacionales** son aquellas que no se basan en el modelo relacional y pueden tener diferentes estructuras, como documentos, gráficos, clave-valor, entre otros.

Existen lenguajes de consulta para interactuar con las bases de datos, como SQL (Structured Query Language) para las bases de datos relacionales y NoSQL (*Not only SQL*) para las bases de datos no relacionales.

Aunque existen paqueterias en Python para interactuar con bases de datos, en este curso nos enfocaremos en la manipulación de datos con Pandas, una librería de Python que nos permite manipular datos de manera sencilla y eficiente. Los datos que cargarémos en este curso son datos en formato CSV, que es un formato de archivo que se utiliza para almacenar datos en forma de tabla.

A diferencia de las bases de datos, los datos en formato CSV no tienen un motor de base de datos que nos permita interactuar con ellos. Por lo tanto, no podemos hacer consultas con SQL, pero podemos manipular los datos con Pandas.


# Manipulación de datos con Pandas

Pandas es una librería de Python que nos permite manipular datos de manera sencilla y eficiente. En este tutorial aprenderemos a leer, escribir y manipular datos con Pandas. Para leer datos, Pandas soporta una gran variedad de formatos, entre los que se encuentran CSV, Excel, JSON, entre otros.

Podemos leer los datos de manera local o por medio de una url que contenga los datos en bruto, en otro caso tendremos que ya sea descargar el archivo o usar librerias como requests para obtener los datos. En este caso leeremos los datos de una url desde el github de este curso. Para leer los datos en formato CSV, usamos la función `pd.read_csv()` de Pandas.

```{python}
import pandas as pd # Primero importamos la librería

url = 'https://raw.githubusercontent.com/Christian-F-Badillo/Ciencia-de-datos-con-Python-de-estadistica-descriptiva-a-redes-neuronales/main/data/archive/mushroom_cleaned.csv' # Definimos la URL del archivo CSV

data = pd.read_csv(url) # Leemos el archivo CSV
```

Si tuvieramos un archivo CSV en nuestra computadora, podríamos leerlo de la siguiente manera:

```python
archivo = 'directorio/subdirectorio/archivo.csv' # Definimos la ruta del archivo CSV

data = pd.read_csv(archivo) # Leemos el archivo CSV
```

## Explorando los datos

Primero como ya vimos en la lección anterior, podemos ver las primeras filas de los datos con el método `head()`. En este caso tenemos datos de hongos, donde cada fila representa un hongo y cada columna una característica del hongo.

Las columnas son las siguientes:

- **Cap Diameter**: Diámetro del sombrero.
- **Cap Shape**: Forma del sombrero.
- **Gill Attachment**: Tipo de unión de las branquias.
- **Gill Color**: Color de las branquias.
- **Stem Height**: Altura del tallo.
- **Stem Width**: Ancho del tallo.
- **Stem Color**: Color del tallo.
- **Season**: Temporada en la que se encontró el hongo.
- **Class**: Si es comestible (0) o venerenoso (1).

```{python}
data.head()
```

Lo primero que podemos hacer es ver la forma de los datos, es decir, cuántas filas y columnas tenemos. Para esto usamos el atributo `shape`.

```{python}
data.shape
```

Tenemos 54039 y 9 columnas en nuestros datos. Podemos ver los nombres de las columnas con el atributo `columns`.

```{python}
data.columns
```

También podemos ver los tipos de datos de las columnas con el atributo `dtypes`.

```{python}
data.dtypes
```

El tipo de dato es muy importante, ya que restringe las cosas que podemos hacer con los datos. En este dataset, tenemos datos tipo `int64` y `float64` que son enteros y décimales respectivamente. El tipo de dato más común en Pandas es `object`, que es un tipo de dato genérico que puede contener cualquier tipo de dato, no es recomendable tener columnas con este tipo de dato, ya que puede ser un indicio de que los datos no están limpios.

Con el metodo `info()` podemos ver un resumen de los datos, incluyendo el número de valores no nulos y el uso de memoria.

```{python}
data.info()
```

Gracias a este método podemos ver que no tenemos valores nulos en nuestro dataset. Si tuvieramos valores nulos, tendríamos que decidir si eliminarlos, reemplazarlos o imputarlos (usar un valor promedio, mediana, moda, etc. para reemplazar los valores nulos).

Para identificar los valores `NA` en los datos, podemos usar el método `isna()`, combinado con el método `sum()` para ver el número de valores `NA` en cada columna.

```{python}
data.isna().sum()
```

Podemos identificar los valores únicos de una columna con el método `unique()`. Por ejemplo, si queremos ver los valores únicos de la columna `class`, podemos hacer lo siguiente:

```{python}
data['class'].unique()
```

En este caso, los valores únicos son 0 y 1, que representan si el hongo es comestible o venenoso. Podemos ver los valores únicos de todas las columnas con el método `unique()`.

## Estadísticas descriptivas

Podemos obtener estadísticas descriptivas de los datos numéricos con el método `describe()`.

```{python}
data.describe()
```

Por comodidad se suele usar el método `transpose()` para ver las estadísticas descriptivas de manera vertical, una abreviatura de esto es `.T`.

```{python}
data.describe().T
```

Algunas estadísticas descriptivas que obtenemos son:

- **count**: Número de valores no nulos.
- **mean**: Media de los valores.
- **std**: Desviación estándar de los valores.
- **min**: Valor mínimo.
- **25%**: Primer cuartil.
- **50%**: Mediana.
- **75%**: Tercer cuartil.
- **max**: Valor máximo.

Podemos guardar estas estadísticas en un nuevo DataFrame para manipularlas más adelante.

```{python}
estadisticas = data.describe().T
```

Si recuerdan sus cursos de estadística una medida de dispersión es el rango, que es la diferencia entre el valor máximo y el valor mínimo. Podemos calcular el rango de los datos restándo el valor máximo y el valor mínimo de cada columna y guardarlo en una nueva columna llamada `rango`.

```{python}
estadisticas['rango'] = estadisticas['max'] - estadisticas['min']
estadisticas.head(9)
```

Otro estadístico importante es la varianza, que es una medida de dispersión que nos indica qué tan dispersos están los datos. Podemos calcular la varianza de los datos con el método `var()` y guardarla en una nueva columna llamada `varianza`.

```{python}
estadisticas['varianza'] = data.var()
estadisticas.head(9)
```

Un último estadístico es el rango intercuartil (IQR), que es la diferencia entre el tercer cuartil y el primer cuartil. Podemos calcular el IQR de los datos al restar las columnas `75%` y `25%` y guardar el resultado en una nueva columna llamada `IQR`.

```{python}
estadisticas['IQR'] = estadisticas['75%'] - estadisticas['25%']

estadisticas.head(9)
```

Podemos ver que hemos calculado el rango, la varianza y el IQR de los datos. Estos estadísticos nos dan una idea de la dispersión de los datos y nos ayudan a entender mejor los datos.

Otro estadtico importante es la correlación, que nos indica la relación entre dos variables. Podemos calcular la correlación de los datos con el método `corr()`.

```{python}
correlacion = data.corr()
correlacion
```


## Filtrando datos

Podemos filtrar los datos de acuerdo a una condición. Por ejemplo, si queremos ver los hongos que son venenosos, podemos filtrar los datos de la siguiente manera:

```{python}
venenosos = data[data['class'] == 1]
venenosos.head()
```

La notación para realizar filtrado en pandas es `df[df['columna'] == valor]`, donde `df` es el DataFrame, `columna` es la columna que queremos filtrar y `valor` es el valor que queremos filtrar.

Podemos hacer filtrados más complejos, por ejemplo, si queremos ver los hongos venenosos que tienen un diámetro de sombrero mayor a su media, podemos hacer lo siguiente:

```{python}
venenosos_grandes = data[(data['class'] == 1) & (data['cap-diameter'] > data['cap-diameter'].mean())]

venenosos_grandes.head()
```

La sintaxis en este caso es `df[(df['columna1'] == valor1) & (df['columna2'] > valor2)]`, donde `&` es el operador lógico `AND` y cada condición va entre paréntesis. Es recomendable no usar más de dos condiciones en un filtro, ya que puede ser difícil de leer.

Otras operaciones lógicas que podemos usar son `|` para el operador `OR` y `~` para el operador `NOT`. Por ejemplo, si queremos ver los hongos que son venenosos o que tienen un diámetro de sombrero mayor a su media, podemos hacer lo siguiente:

```{python}
venenosos_o_grandes = data[(data['class'] == 1) | (data['cap-diameter'] > data['cap-diameter'].mean())]

venenosos_o_grandes.head()
```

## Ordenando datos

Podemos ordenar los datos de acuerdo a una columna. Por ejemplo, si queremos ordenar los hongos por su diámetro de sombrero de manera ascendente, podemos hacer lo siguiente:

```{python}
data.sort_values(by='cap-diameter').head()
```

Hemos utilizado el método `sort_values()` para ordenar los datos de acuerdo a la columna `cap-diameter`. Por defecto, el método ordena de manera ascendente, pero podemos cambiarlo a descendente con el argumento `ascending=False`. El argumento `by` es la columna por la que queremos ordenar los datos. Si queremos ordenar los datos de manera descendente, podemos hacer lo siguiente:

```{python}
data.sort_values(by='cap-diameter', ascending=False).head()
```

Para ordenar con múltiples columnas, podemos pasar una lista de columnas al argumento `by`. Por ejemplo, si queremos ordenar los hongos por su diámetro de sombrero de manera ascendente y por su altura de tallo de manera descendente, podemos hacer lo siguiente:

```{python}
data.sort_values(by=['cap-diameter', 'stem-height'], ascending=[True, False], kind="mergesort").head(10)
```

Con el argumento `kind` podemos especificar el algoritmo de ordenamiento. En este caso hemos usado `mergesort`, que es un algoritmo de ordenamiento estable y eficiente. Otros algoritmos que podemos usar son `quicksort` y `heapsort`.

El ordenamiento con más de una columna es útil cuando queremos ordenar los datos de acuerdo a una columna y en caso de empate, ordenarlos de acuerdo a otra columna. En este caso, primero ordenamos los datos de acuerdo a la columna `cap-diameter` y en caso de empate, ordenamos los datos de acuerdo a la columna `stem-height`. Podemos comprobarlo viendo los primeros 10 datos.

## Agrupando datos

Podemos agrupar los datos de acuerdo a una columna. Por ejemplo, si queremos agrupar los hongos por su color de tallo y ver cuántos hongos hay de cada color, podemos hacer lo siguiente:

```{python}
data.groupby('stem-color').size()
```

El método `groupby()` agrupa los datos de acuerdo a una columna y el método `size()` nos da el tamaño de cada grupo. En este caso, hemos agrupado los hongos por su color de tallo y hemos obtenido el tamaño de cada grupo.

Otro método que podemos usar es `count()`, que nos da el número de valores no nulos de cada columna.

```{python}
data.groupby('stem-color').count()
```

La diferencia es que `size()` nos da el tamaño de cada grupo, mientras que `count()` nos da el número de valores no nulos de cada columna.

Para hacer operaciones más complejas, podemos usar el método `agg()`, que nos permite aplicar una o más funciones a cada grupo. Por ejemplo, si queremos obtener la media y la mediana del diámetro de sombrero de cada grupo, podemos hacer lo siguiente:

```{python}
data.groupby('stem-color')['cap-diameter'].agg(['mean', 'median'])
```

En este caso, hemos agrupado los hongos por su color de tallo y hemos obtenido la media y la mediana del diámetro de sombrero de cada grupo.

## Guardando datos

Podemos guardar los datos en un archivo CSV con el método `to_csv()`. Por ejemplo, si queremos guardar los datos en un archivo llamado `mushroom.csv`, podemos hacer lo siguiente:

```{python}
#data.to_csv('mushroom.csv', index=False)
```

El argumento `index=False` evita que se guarde el índice en el archivo CSV. Existen otros formatos en los que podemos guardar los datos, como Excel, JSON, entre otros. Para guardar los datos en un archivo Excel, podemos usar el método `to_excel()`.
```{python}
#data.to_excel('mushroom.xlsx', index=False)
```

Para guardar los datos en un archivo JSON, podemos usar el método `to_json()`. 

```{python}
#data.to_json('mushroom.json', orient='records')
```

## Ejericios

Creen un documento de Jupyter Notebook por equipo y resuelvan los siguientes ejercicios, utilicen Markdown para explicar sus respuestas y comentarios en el código. Se sugiere la creación de funciones para resolver los ejercicios.

1. Carga los datos de Iris desde la siguiente liga "https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv" y muestra las primeras 10 filas, muestra la forma de los datos, los nombres de las columnas, los tipos de datos, el tamaño de los datos y si hay valores nulos (`NA`).
   
2. Calcula las estadísticas descriptivas de los datos.

3. Filtra los datos para obtener las flores que tienen un ancho de pétalo mayor a su media, mediana, media y mediana. Impreme las primeras 10 filas.

4. Ordena los datos de acuerdo a la longitud de sépalo de manera ascendente y de acuerdo a la longitud de pétalo de manera descendente. Muestra las primeras 10 filas.

5. Filtra los datos para obtener las flores que tienen un ancho de pétalo mayor a su media y que son de la especie `setosa`. Muestra las primeras 10 filas.

6. Agrupa los datos por especie y calcula los estadísticos descriptivos de cada grupo (media, mediana, moda, varianza, rango, IQR). Muestra los resultados.

7. Guarda los datos de los estadísticos descriptivos del ejercicio 2 en un archivo CSV, Excel y JSON.

8. Calcula la correlación de los datos y muestra los resultados.

9. Sugiere que gráficos podrías hacer con los datos y que información podrías obtener de ellos.

10. Explica ¿qué análisis podrías hacer con los datos?, ¿qué preguntas podrías responder con los datos?

# Conclusiones

La manipulación de datos es una parte fundamental de la ciencia de datos, ya que nos permite limpiar, transformar y analizar los datos para obtener información útil. En este tutorial hemos aprendido a leer, escribir y manipular datos con Pandas. Hemos visto cómo explorar los datos, obtener estadísticas descriptivas, filtrar los datos, ordenar los datos, agrupar los datos y guardar los datos en diferentes formatos. Estas son habilidades básicas que nos permiten trabajar con los datos de manera eficiente y efectiva.